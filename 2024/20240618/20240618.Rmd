---
title: "Semisynthetic Simulation for Biological Data Analysis"
author: "Kris Sankaran"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)
library(knitr)
library(RefManageR)
library(tidyverse)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3)
min_theme <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    strip.text = element_text(size = 16),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(min_theme)

# overwrite some default scales in ggplot2
scale_fill_continuous <- function(...) scico::scale_fill_scico(..., palette = "lapaz", direction = -1)
scale_colour_discrete <- function(...) ggplot2::scale_color_brewer(..., palette = "Set2")
scale_x_continuous <- function(...) ggplot2::scale_x_continuous(..., expand = c(0, 0))
scale_y_continuous <- function(...) ggplot2::scale_y_continuous(..., expand = c(0, 0))

BibOptions(
  check.entries = FALSE, 
  bib.style = "numeric", 
  cite.style = "numeric", 
  style = "markdown",
  hyperlink = FALSE, 
  dashed = FALSE
)
bib <- ReadBib("references.bib")
```


<div id="title">
Semisynthetic Simulation for Biological Data Analysis
</div>
<div id="under_title">
Session 2: Multivariate Analysis
</div>


<div id="subtitle">
Kris Sankaran <br/>
18 | June | 2024 <br/>
Lab: <a href="https://go.wisc.edu/pgb8nl">go.wisc.edu/pgb8nl</a> <br/>
</div>

<div id="subtitle_right">
Melbourne Integrative Genomics<br/>
Slides: <a href="https://go.wisc.edu/rc776i">go.wisc.edu/rc776i</a><br/>
Code: <a href="https://go.wisc.edu/o5sn6w">go.wisc.edu/o5sn6w</a>
</div>

---

### Today's Learning Outcomes

By the end of this session, you will be able to...

1. Design and implement power and benchmarking analyses for multivariate models.
1. Discuss factor models and at least two copula variants for simulating correlated data.
1. Compare and contrast the scientific contexts where multivariate and
univariate models are more appropriate.

---

class: middle

.center[
## Scientific Context
]

---

### Multivariate Modeling

* Features in high-throughput biological data are strongly correlated. Focusing on
marginals alone would keep us from understanding important relationships.

* Multivariate thinking can inform higher-level conceptual categories:
regulatory modules, microbial communities, cell types,  ...

.center[
<img src="figure/eisen.png" width=650/>
<br/>
  <span style="font-size: 20px">
    A heatmap of microarray data from `r Citep(bib, "Eisen1998-zl")`
  </span>
]

---

### Examples Analyses

These methods are often based on some form of matrix factorization, and they are
ubiquitous in modern genomics:

* Clustering: Cancer subtypes, cell atlases `r Citep(bib, c("Quake2022-qv", "Luecken2022-tj"))`.
* Dimensionality Reduction: Microbiome communities `r Citep(bib, c("Sankaran2019-tw", "Deek2020-zo"))`, pseudotime analysis `r Citep(bib, c("Street2018-pf", "Xia2019-ei"))`
* Network Analysis: Gene regulatory networks `r Citep(bib, c("Wu2016-gf", "Duren2018-ik"))`.

<span style="font-size: 20px"/>
Example Methods: Multidimensional Scaling, Principal Components Analysis,
Uniform Manifold Approximation and Projection, Nonnegative Matrix Factorization,
Mixed-Membership Modeling, Stochastic Blockmodel, ...
</span>

---

### Role of Simulation

Simulation can be valuable even in this multivariate setting.

* **Power Analysis**: How does the likely number of discoveries vary as we vary the sample size and experimental design?

* **Benchmarking**: For a given multivariate analysis output, what are tradeoffs between candidate methods?

* **Calibration**: Can conclusions be adjusted to ensure that target false discovery rates
are closely met on synthetic data?

---

### Discussion

Please discuss in groups of 2 - 4: 

* In your research, where can you use multivariate methods?
* How might simulation assist that analysis?

We will debrief responses as a group.

---

class: middle
.center[
  ## Statistical Background
]

---

### Latent Variables

This approaches identifies low-dimensional profiles that underlie all observed
variation. 

.center[
<img src="figure/latent_approaches.png" width=400/>
]

---

### Matrix Factorization

This can be accomplished using a form of matrix factorization `r Citep(bib, c("Stein-OBrien2018-pu", "Murphy2023-ej"))`: 
\begin{align*}
x_{i} \approx A z_{i}
\end{align*}

  * In clustering, $z_{i}$ encode which cluster sample $i$ belongs to.
  * In PCA, $z_i$ are scores with respect to components $A$.

.center[
<img src="figure/matrix_factorization.png" width=550/>
]

---

### Matrix Factorization

This can be accomplished using a form of matrix factorization `r Citep(bib, c("Stein-OBrien2018-pu", "Murphy2023-ej"))`: 
\begin{align*}
x_{i} \approx A z_{i}
\end{align*}

  * In clustering, $z_{i}$ encode which cluster sample $i$ belongs to.
  * In PCA, $z_i$ are scores with respect to components $A$.

.center[
<img src="figure/clustering.png" width=550/>
]

---

### Matrix Factorization

This can be accomplished using a form of matrix factorization `r Citep(bib, c("Stein-OBrien2018-pu", "Murphy2023-ej"))`: 
\begin{align*}
x_{i} \approx A z_{i}
\end{align*}


  * In clustering, $z_{i}$ encode which cluster sample $i$ belongs to.
  * In PCA, $z_i$ are scores with respect to components $A$.

.center[
<img src="figure/factorization.png" width=550/>
]

---

### Implications

This suggests a simulation strategy:

.pull-left[
* Learn $\mathbf{z}_{i}$ from real data.
* For each $d$, learn the marginal $F_{d}\left(x_{id} \vert \mathbf{z}_{i}\right)$ using GAMLSS.
* To generate new $\mathbf{x}^{\ast}$, first simulate $\mathbf{z}^\ast$ and sample from $\left[F_{1}\left(\cdot \vert \mathbf{z}^\ast\right), \dots, F_{D}\left(\cdot \vert \mathbf{z}^\ast\right)\right]$
]

.pull-right[
<img src="figure/clustering_pushforward.png" width=500/>
]

---

### Copula Models

These are a type of model that "couple" a collection of known marginal
distributions `r Citep(bib, c("Joe2023-xb", "Deek2023-dc", "Sun2021-lg"))`.

.center[
<img src="figure/gene-gene_dependence.png" width=900/>
]

---

### Starting Point

**Question**: If we were asked to simulate a vector of five correlated variables on
our computers right now, what would be the easiest thing to do?

---

### Starting Point

**Question**: If we were asked to simulate a vector of five correlated variables on
our computers right now, what would be the easiest thing to do?

```{r}
library(mvtnorm)
D <- 5
ones <- rep(1, D)
Sigma <- 0.01 * diag(D) + 0.99 * ones %*% t(ones)
rmvnorm(3, rep(0, D), Sigma)
```

The difficulty is that we usually want non-Gaussian margins $F_{1}, \dots, F_{D}$.

---

### Intuition

* In the Gaussianized space, it's easy to model correlation.
* The mapping back and forth is possible because we know the margins $F$.
  - $\Phi$ represents the Gaussian CDF applied componentwise
<br/>
<br/>

.center[
<img src="figure/copula_transformation.png" width=700/>
]

---

### Copula Models

More formally, let $F_{1}, \dots, F_{D}$ be the target margins and let $\Phi$ be
the CDF of the Gaussian distribution. Gaussian Copula modeling has these steps.

Estimate:

1. Gaussianize the observed $\mathbf{x}_{i}$ to $\mathbf{z}_{i} := \left[\Phi^{-1}\left(F_{1}\left(x_{i1}\right)\right), \dots, \Phi^{-1}\left(F_{D}\left(x_{iD}\right)\right)\right]$
1. Estimate the covariance $\hat{\Sigma}$ associated with $z_{i}$

Simulate:

1. Draw $\mathbf{z}^\ast \sim \mathcal{N}\left(0, \Sigma\right)$ 
1. Transform back $\mathbf{x}\ast := \left[F_{1}^{-1}\left(\Phi\left(z_{i1}^\ast\right)\right), \dots, F_{D}^{-1}\left(\Phi\left(z_{iD}^\ast\right)\right)\right]$

---

### Variations

1. We might expect the corelation structure to vary across groups. This can be
accomplished by setting separate $\Sigma_{k}$ across groups $k$.

1. In high-dimensions, the sample covariance $\hat{\Sigma}$ can destabilize. In
this case, we should use high-dimensional covariance estimators `r Citep(bib, c("Meinshausen2006-cg,", "Friedman2008-cw", "Cai2011-ja"))`.

.center[
<img src="figure/copula_groups.png" width=700/>
]

---

### Definition

Last session's code actually estimated Gaussian copulas in the background by default.

```{r, eval = FALSE}
setup_simulator(
  exper, 
  ~ group, 
  ~ GaussianLSS(),
  copula_gaussian()
)
```

---

### Conditioned Copulas

We can allow the covariance to depend on group membership using the same formula
syntax we used for the marginals.

```{r, eval = FALSE}
setup_simulator(
  exper, 
  ~ group, 
  ~ GaussianLSS(),
  copula_gaussian(~ group)
)
```

---

### Available Copulas

* `copula_adaptive`: Adaptive estimation of high-dimensional covariance estimation `r Citep(bib, "Cai2011-ja")`.
* `copula_vine`: Vine copula for matching higher-order moments `r Citep(bib, "Czado2022-zn")`.
* `copula_glasso`: Graphical Lasso for sparse covariance estimation `r Citep(bib, "Friedman2008-cw")`.
* `copula_t`: Student's $t$ Copula for better modeling of tail-dependence
* `copula_*_t`: Modified covariance estimators applied to $t$ Copula

---


### sPLS-DA Setting

Our power analysis uses Sparse Parital Least Squares Discriminant Analysis
(sPLS-DA) `r Citep(bib, c("Le_Cao2008-zz", "Le_Cao2011-kn", "Rohart2017-sa"))`. This topic is it's
own full workshop, but let's review the core ideas.

.pull-left[
sPLS-DA helps with prediction when, 

* s: Not all features are predictive
* PLS: Many features are correlated with one another
* DA: The response is one of $K$ classes
]

.pull-right[
<img src="figure/PLS-setup.png" width=500/>
]

---

### sPLS-DA Intuition

We "blend" columns of $\mathbf{X}$ and $\mathbf{Y}$ within tables until the patterns look similar.

.center[
<img src="figure/PLS-step1.png" width=500/>
]

Formally, choose weights $\mathbf{a}$ and $\mathbf{b}$ to maximize
$\text{cor}\left(\mathbf{Xa}, \mathbf{Yb}\right)$.

---

### sPLS-DA Intuition

We "blend" columns of $\mathbf{X}$ and $\mathbf{Y}$ within tables until the patterns look similar.

.center[
<img src="figure/PLS-step2.png" width=240/>
]

Formally, choose weights $\mathbf{a}$ and $\mathbf{b}$ to maximize
$\text{cor}\left(\mathbf{Xa}, \mathbf{Yb}\right)$.


---

### sPLS-DA Intuition

We "blend" columns of $\mathbf{X}$ and $\mathbf{Y}$ within tables until the patterns look similar.

.center[
<img src="figure/PLS-step3.png" width=400/>
]

Formally, choose weights $\mathbf{a}$ and $\mathbf{b}$ to maximize
$\text{cor}\left(\mathbf{Xa}, \mathbf{Yb}\right)$.

---

### sPLS-DA Intuition

We "blend" columns of $\mathbf{X}$ and $\mathbf{Y}$ within tables until the patterns look similar.

.center[
<img src="figure/PLS-step4.png" width=150/>
]

Formally, choose weights $\mathbf{a}$ and $\mathbf{b}$ to maximize
$\text{cor}\left(\mathbf{Xa}, \mathbf{Yb}\right)$.

---

### sPLS-DA Intuition

Now we can compare samples from the two tables in a single, shared space.

.center[
<img src="figure/PLS-step5.png" width=800/>
]

---

### sPLS-DA Intuition

Now we can compare samples from the two tables in a single, shared space.

.center[
<img src="figure/PLS-step6.png" width=800/>
]

---

### sPLS-DA Intuition

To get more than one dimension, we can repeat this process after removing any
correlation with previously found patterns.

.center[
<img src="figure/PLS-step7.png" width=800/>
]

---

### sPLS-DA: Outputs

The blending coefficients tell you how to interpret axes in this space.  For
example, $a^{(1)}_{d} = 0$ means feature $d$ wasn't used for the first
dimension.

.pull-left[
```{r, echo = FALSE, fig.height = 3, fig.width = 4.5}
library(mixOmics)
set.seed(5249)
data(srbct) # extract the small round bull cell tumour data
X <- srbct$gene # use the gene expression data as the X matrix
Y <- srbct$class # use the class data as the Y matrix
srbct.splsda <- splsda(X, Y, ncomp = 10)  # set ncomp to 10 for performance assessment later
plotIndiv(srbct.splsda)
```
]

.pull-right[
```{r, echo = FALSE, fig.height = 3, fig.width = 4.5}
var.name.short <- substr(srbct$gene.name[, 2], 1, 10) # form simplified gene names
plotVar(srbct.splsda, var.names = list(var.name.short), cex = 3, cutoff = 0.6)
```
]
Example sPLS-DA output from the `mixOmics` package `r Citep(bib, "Rohart2017-sa")`.

---


class: middle

.center[
## Demo + Exercises
]

* Code repository: [go.wisc.edu/o5sn6w](https://go.wisc.edu/o5sn6w)
* Exercise solutions: [go.wisc.edu/441a60](https://go.wisc.edu/441a60)
* Live Link: 
---

### Summary

1. Multivariate analysis is essential for reasoning about higher-level concepts
in biological data.
1. Copula and factor models are general approaches to inducing correlation in
simulated data.
1. The `copula_*` functions in `scDesigner` give a few approaches to copula-based simulation
1. Power analysis can be tightly coupled with multivariate algorithms.

---

### Next Time

Marginal $\to$ Joint $\to$ <span style="color:#8C1F33">Integrative</span>

.center[
<img src="figure/integration_types_3.png" width=600/>
]

---

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 1, end = 4)
```

---

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 5, end = 8)
```

---

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 9, end = 12)
```

---

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 13, end = 20)
```

---

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 18, end = 22)
```
