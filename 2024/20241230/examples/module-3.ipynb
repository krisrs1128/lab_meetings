{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "import captum as cp\n",
    "import captum.concept._utils.data_iterator as di\n",
    "import glob\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(filename):\n",
    "    img = PIL.Image.open(filename).convert(\"RGB\")\n",
    "    return transform(img)\n",
    "\n",
    "def transform(img):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )(img)\n",
    "\n",
    "def load_tensors(class_name, root_path=\"data/concepts/\", transform=True):\n",
    "    path = Path(root_path) / class_name\n",
    "    filenames = glob.glob(str(path / '*.jpg'))\n",
    "\n",
    "    tensors = []\n",
    "    for filename in filenames:\n",
    "        img = PIL.Image.open(filename).convert('RGB')\n",
    "        tensors.append(transform(img) if transform else img)\n",
    "    return tensors\n",
    "\n",
    "def assemble_concept(name, id, concept_path):\n",
    "    dataset = di.CustomIterableDataset(load_tensor, f\"{str(concept_path / name)}/\")\n",
    "    concept_iter = di.dataset_to_dataloader(dataset)\n",
    "    return cp.concept.Concept(id=id, name=name, data_iter=concept_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_path = Path(\"data/concepts/\")\n",
    "stripes_concept = assemble_concept(\"striped\", 0, concept_path=concept_path)\n",
    "dotted_concept = assemble_concept(\"dotted\", 1, concept_path=concept_path)\n",
    "random0_concept = assemble_concept(\"random500_0\", 2, concept_path=concept_path)\n",
    "random1_concept = assemble_concept(\"random500_1\", 3, concept_path=concept_path)\n",
    "random2_concept = assemble_concept(\"random500_2\", 4, concept_path=concept_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=['inception4c', 'inception4d', 'inception4e']\n",
    "\n",
    "mytcav = cp.concept.TCAV(\n",
    "    model=model, \n",
    "    layers=layers,\n",
    "    layer_attr_method=cp.attr.LayerIntegratedGradients(model, None, multiply_by_inputs=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zebra_images = load_tensors('zebra', transform=False)\n",
    "zebra_tensors = torch.stack([transform(img) for img in zebra_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = [[stripes_concept, random0_concept]]\n",
    "\n",
    "ix = 340\n",
    "tcav_scores = mytcav.interpret(\n",
    "    inputs=zebra_tensors, \n",
    "    experimental_sets=classification_data,\n",
    "    n_steps=5,\n",
    "    target=ix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = [[stripes_concept, dotted_concept]]\n",
    "\n",
    "ix = 340\n",
    "tcav_scores = mytcav.interpret(\n",
    "    inputs=zebra_tensors, \n",
    "    experimental_sets=classification_data,\n",
    "    n_steps=5,\n",
    "    target=ix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
