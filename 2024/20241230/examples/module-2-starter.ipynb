{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Explaining Models (ALE, MDI+)\n",
    "\n",
    "In this note will revisit the income prediction problem to form global, rather\n",
    "than local, explanations. We will use the `alibi` and `imodels` packages to\n",
    "create ALE and MDI+ summaries, respectively. The ALE plots will apply to the\n",
    "same gradient boosting model from our previous example, while MDI+ will be\n",
    "tailored for a new random forest model. If you setup the conda environment from\n",
    "the previous module, you can continue to use it (environment `iisa310`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import ALE, plot_ale\n",
    "import lightgbm as lgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we generate the ALE summary, let's refit the same gradient boosting model from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.adult()\n",
    "data = lgb.Dataset(X, y)\n",
    "model = lgb.train({\"learning_rate\": 0.05}, data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALE takes the model's prediction function and the list of potential features as\n",
    "input. Given the ALE object, we can form the ALE plot for any individual feature\n",
    "its associated `.explain` method, and we can use the package's built in function\n",
    "to plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define an ALE object and explanation for features 0 [Age] and 8 [Capital Gain]\n",
    "ale = #???\n",
    "explanation = #???\n",
    "\n",
    "# plot the resulting explanation\n",
    "plot_ale(explanation, sharey=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALE applies to any model. In contrast, MDI+ can only apply to tree-based models.\n",
    "The code below fits a new random forest+ model to the same income prediction\n",
    "problem. The random forest+ model fits a linear model using features derived\n",
    "from the original random forest model. Since the problem is classification, this\n",
    "is just a logistic regression model applied to tree features. We're fitting a\n",
    "quite small model to just a subset of the data, because we want this code to run\n",
    "relatively quickly. Of course, using all samples would lead to more precise MDI+\n",
    "scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imodels.importance import RandomForestPlusClassifier\n",
    "import numpy as np\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "model = RandomForestPlusClassifier(rf_model=classifier)\n",
    "ix = np.random.choice(X.index, size=1000)\n",
    "model.fit(X.loc[ix, :], y[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block above fit the original model, adn we can use the `get_mdi_plus_scores`\n",
    "wrapper method to get scores for each feature. Note that, in our original\n",
    "discussion, these are just $R^{2}$ values between the full and\n",
    "$k^{\\text{th}}$-submodel predictions, because there we had been focused on\n",
    "regression problesm. Here, though, we are using classification. In this case,\n",
    "the package uses the negative binary cross entropy between the full and\n",
    "$k^{\\text{th}}$ submodel predictions. A cross entropy value closer to 0 means\n",
    "that using that subset alone can nearly recover the original, full model\n",
    "probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi_plus_scores = model.get_mdi_plus_scores(X.iloc[ix, :], y[ix])\n",
    "mdi_plus_scores.sort_values(by='importance', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iisa310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
