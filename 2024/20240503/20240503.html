<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Multiscale Analysis of Microbiome Data with Alto</title>
    <meta charset="utf-8" />
    <meta name="author" content="Kris Sankaran" />
    <script src="libs/header-attrs-2.26/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


`\(\def\Dir{\text{Dir}}\)`
`\(\def\Mult{\text{Mult}}\)`
`\(\def\*#1{\mathbf{#1}}\)`
`\(\def\m#1{\boldsymbol{#1}}\)`
`\(\def\Unif{\text{Unif}}\)`
`\(\def\win{\tilde{w}_{\text{in}}}\)`
`\(\def\reals{\mathbb{R}}\)`
`\(\newcommand{\wout}{\tilde w_{\text{out}}}\)`




## Multiscale Analysis of Microbiome Data with Alto

&lt;div id="subtitle"&gt;
Kris Sankaran &lt;br/&gt;
&lt;a href="https://go.wisc.edu/pgb8nl"&gt;go.wisc.edu/pgb8nl&lt;/a&gt; &lt;br/&gt;
03 | May | 2024 &lt;br/&gt;
&lt;/div&gt;

&lt;div id="subtitle_right"&gt;
STATGEN 2024 &lt;br/&gt;
Microbiome Data Analysis
&lt;/div&gt;

---

### Iterative Data Structuration

.pull-left[
* Iterative data structuration creates a sequence of simple `\(\to\)` complex models(Holmes, 1993; Mallows et al., 1982)
* It is the statistical analog of the Focus-plus-Context visualization principle (Hauser et al., 2004; Heer et al., 2004)
* Begin with the overview (context), then focus on residual variation (focus)
]

.pull-right[
&lt;div class="figure" style="text-align: left"&gt;
&lt;img src="figure/structuration.png" alt="A metaphor for structuration, from (Holmes, 1993)." width="340" /&gt;
&lt;p class="caption"&gt;A metaphor for structuration, from (Holmes, 1993).&lt;/p&gt;
&lt;/div&gt;
]

---

### Latent Dirichlet Allocation

Latent Dirichlet Allocation (Blei et al., 2003) supposes that samples `\(x_i \in \mathbb{R}^{D}\)`
are drawn independently from,

`\begin{align*}
x_i \vert \gamma_i &amp;\sim \text{Mult}\left(n_{i}, \*B\gamma_{i}\right) \\
\gamma_{i} &amp;\sim \text{Dir}\left(\lambda_{\gamma} 1_{K}\right)
\end{align*}`
where the columns `\(\beta_{k}\)` of `\(\*B \in \Delta^{K}_{D}\)` lie in the `\(D\)`-dimensional simplex and are themselves drawn independently from,
`\begin{align*}
\beta_{k} \sim \text{Dir}\left(\lambda_{\beta} 1_{D}\right).
\end{align*}`

We vertically stack the `\(N\)` `\(\gamma_i\)`'s into `\(\gamma \in \Delta^{N}_{K}\)`.

---

### Latent Dirichlet Allocation

Topic models are well-suited to count data dimensionality reduction. The
estimated parameters can be interpreted as,
* `\(\Gamma \in \Delta_{K}^{N}\)`: Per-document memberships across `\(K\)` topics.
* `\(\*B \in \Delta_{D}^{K}\)`: Per topic distributions over `\(D\)` words.
* `\(K\)` = Number of topics = Number of extreme points

&lt;img src="figure/latent_dirichlet_v2.png" width="430" style="display: block; margin: auto;" /&gt;

---

### Managing Large `\(K\)`

* It is often difficult to interpret these models when `\(K\)` is large
* Heuristic: Look at smaller `\(K\)` to build intuition about topics
  - Then analyze deviations between topics at coarse and fine scales
  - This is guided by iterative data structuration

&lt;img src="figure/latent_dirichlet_v2.png" width="430" style="display: block; margin: auto;" /&gt;

---

### Main Idea

* We will fit an ensemble of models of varying complexities (Parsimony)
* We will build a compact representation of the result (Navigation)
* In the Sankey diagram, columns are models and rectangles are topics

&lt;img src="figure/alto_sketches_annotated alignment.png" width="750" style="display: block; margin: auto;" /&gt;

---

### Alignment as a Graph

We view an alignment as a graph across the ensemble. Index models by `\(m\)` and
topics by `\(k\)`. Then,
* Nodes `\(V\)` correspond to topics, parameterized by `\(\{\beta^m_{k}, \gamma^m_{k}\}\)`
* Edges `\(E\)` are placed between topics from neighboring models, i.e. `\(K\)` to `\(K + 1\)`
* Weights `\(W\)` encode the similarity between topics

&lt;img src="figure/alto_sketches_annotated alignment.png" width="560" style="display: block; margin: auto;" /&gt;

---

### Notation

This graph-based view provides a convenient notation,

* `\(m\left(v\right)\)` is the model for node `\(v\)`
* `\(k\left(v\right)\)` is the topic for node `\(v\)`
* `\(\Gamma\left(v\right) := \left(\gamma_{ v\left(k\right)}^m\left(k\right)\right) \in \reals^n_{+}\)` is the vector of
mixed memberships for topic `\(v\)`
* `\(\beta\left(v\right) := \beta_{k}^m \in \Delta^{D}\)` is the
corresponding topic distribution
* `\(e = \left(v, v'\right)\)` is an edge linking topics `\(v\)` and `\(v'\)`.

&lt;img src="figure/alto_sketches_annotated alignment.png" width="560" style="display: block; margin: auto;" /&gt;

---

### Estimating Weights: Product approach

.pull-left[
To compute weights, we can use,
`\begin{align*}
w\left(e\right) = \Gamma\left(v\right)^T\Gamma\left(v'\right)
\end{align*}`
]

.pull-right[
&lt;img src="figure/product_alignment_conceptual.png" width="500" style="display: block; margin: auto;" /&gt;
]

---

### Estimating Weights: Transport approach

Let `\(V_p\)` and `\(V_q\)` be two subsets of topics within the graph.

* Let the total "mass" of `\(V_p\)` be `\(p = \left\{\Gamma\left(v\right)^T 1 : v \in V_{p}\right\}\)`. Define `\(q\)` similarly.
* Define the transport cost `\(C\left(v, v^\prime\right) := JSD\left(\beta\left(v\right), \beta\left(v^\prime\right)\right)\)`, the Jensen-Shannon divergence between the pair of topic distributions.

&lt;img src="figure/transport_alignment_conceptual.png" width="420" style="display: block; margin: auto;" /&gt;

---

### Estimating Weights: Transport approach


The weights `\(W\)` can be estimated by solving the optimal transport problem,
`\begin{align*}
&amp;\min_{W \in \mathcal{U}\left(p, q\right)} \left&lt;C,W\right&gt; \\
\mathcal{U}\left(p, q\right) := &amp;\{W\in \mathbb{R}^{\left|V_{p}\right| \times \left|V_{q}\right|}_{+} : W 1_{\left|V_{q}\right|} = p \text{ and } W^{T} 1_{\left|V_{p}\right|} = q\}.
\end{align*}`

&lt;img src="figure/transport_alignment_conceptual.png" width="420" style="display: block; margin: auto;" /&gt;

---

### Diagnostics

* Paths: Partitions the Sankey diagram into connected sets of topics
* Coherence: Measures transience of a topic along its path
* Refinement: Reflects degree of mixing between descendant topics

&lt;img src="figure/alto_sketches_diagnotics.png" width="2696" style="display: block; margin: auto;" /&gt;

---

### True LDA Model

Sanity check - What is the alignment when data are generated from LDA? Can you guess the true `\(K\)`?

* `\(N = 250, D = 1000, \lambda_{\gamma} = 0.5, \lambda_{\beta} = 0.1\)`

&lt;img src="figure/transport-true-lda.png" width="480" style="display: block; margin: auto;" /&gt;

---

### Diagnostics

The diagnostics suggest that the true `\(K\)` is 5.

&lt;img src="figure/lda-combined.png" width="2003" style="display: block; margin: auto;" /&gt;

---

The diagnostics become more reliable as the sample size increases.

&lt;img src="figure/summary_alto_asymptotic_behavior.png" width="1000" style="display: block; margin: auto;" /&gt;

---


### LDA with background variation

What happens when the LDA model is mis-specified? Consider the following
generative mechanism,

`\begin{align*}
x_{i} \vert \*B, \gamma_{i}, \nu_i &amp;\sim \Mult\left(n_{i}, \alpha \*B\gamma_{i} + \left(1 - \alpha\right)\nu_i\right) \\
\nu_{i} &amp;\sim \Dir\left(\lambda_{\nu}\right) \\
\gamma_i &amp;\sim \Dir\left(\lambda_{\gamma}\right) \\
\beta_{k} &amp;\sim \Dir\left(\lambda_{\beta}\right),
\end{align*}`

where `\(\*B\)` stacks the `\(\beta_k\)` rowwise.

---

### Result

The alignment structure is sensitive to changes in `\(\alpha\)` and fragments when
LDA structure is not present.

.pull-left[
&lt;img src="figure/gradient_flow-1.png" width="300" style="display: block; margin: auto;" /&gt;&lt;img src="figure/gradient_flow-2.png" width="300" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="figure/gradient_flow-3.png" width="300" style="display: block; margin: auto;" /&gt;&lt;img src="figure/gradient_flow-4.png" width="300" style="display: block; margin: auto;" /&gt;
]

---

### Diagnostics

.pull-left-small[
This structure is consistent across simulation runs, and the diagnostics 
quantify topic deterioration
]
  
.pull-right-large[
&lt;img src="figure/gradient-combined.png" width="635" style="display: block; margin: auto;" /&gt;
]

---

### Strain switching

The final simulation mimics the strain switching problem.
  * Small subsets of species switch between two otherwise similar topics
  * Multiple resolutions are required to detect the difference

---

### Mechanism

We first construct equivalence classes of similar topics `\(\tilde{\beta}_k^r\)`.
Then, for each sample `\(i\)` and each `\(k\)`, we draw one member from the class,

`\begin{align*}
\beta_{k}^{i} &amp;\sim \Unif\left(\left\{\tilde{\beta}_{k}^{1}, \dots, \tilde{\beta}_{k}^{R}\right\}\right)
\end{align*}`

stack the results into `\(\*B^{i}\)`, and then draw,

`\begin{align}
x_{i} &amp;\sim \Mult\left(n_{i}, \*B^{i}\gamma_{i}\right)
\end{align}`
as in standard LDA.

---

### Results
* There are five topics, two of which exhibit strain switching
* At smaller `\(K\)`, we recognize the five main topics
* At larger `\(K\)`, we can distinguish perturbed variants

.pull-left[
&lt;img src="figure/equivalence_flow.png" width="960" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="figure/equivalence_betas.png" width="4320" style="display: block; margin: auto;" /&gt;
]

---

### Results
* At smaller `\(K\)`, we recognize the main community structure, but don't see strain switching
* At larger `\(K\)`, we can recognize instances of switching

&lt;img src="figure/equivalence_similarity_hm.png" width="650" style="display: block; margin: auto;" /&gt;

---

### Data Analysis

.pull-left[
* What role does the microbiome play in preterm birth?
* Ravel et al. (2011) use clustering to identify 5 Community State Types (CSTs)
  - Four healthy CSTs are dominated by Lactobacillus variants
  - A fifth dysbiotic CST is more compositionally diverse
]

.pull-right[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figure/community_state_types.jpg" alt="CSTs as found by Ravel et al. (2011)." width="420" /&gt;
&lt;p class="caption"&gt;CSTs as found by Ravel et al. (2011).&lt;/p&gt;
&lt;/div&gt;
]

---

### Dataset

Consider the 16S modality from the follow-up study (Symul et al., 2023).
.pull-left[
* 135 individuals followed through pregnancy
* 2179 samples and 2699 species
]

.pull-right[

```r
library(alto)
library(purrr)
data(vm_data)
map(vm_data, dim)
```

```
## $sample_info
## [1] 2179   61
## 
## $counts
## [1] 2179 2699
## 
## $taxonomy
## [1] 2699    7
```
]

---

### Interpretations

* At `\(K = 7\)`, the four Lactobacillus CSTs are already present
* The remaining three topics correspond to the dysbiotic CST
(green, brown, and pink)
 
.pull-left[
&lt;img src="figure/microbiome_flow.png" width="280" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="figure/microbiome_betas.png" width="800" style="display: block; margin: auto;" /&gt;
]
 
---

These are the results presented in (Symul et al., 2023).

&lt;img src="figure/example_study.png" width="897" style="display: block; margin: auto;" /&gt;

---

### Software

Topic alignment is implemented in the R package [alto](lasy.github.io/alto).
 
.pull-left[

```r
library(purrr)
library(alto)

# simulate data and fit models
x &lt;- rmultinom(20, 500, rep(0.1, 50))
colnames(x) &lt;- seq_len(ncol(x))
lda_params &lt;- setNames(map(1:10, ~ list(k = .)), 1:10)
lda_models &lt;- run_lda_models(x, lda_params)

# perform alignment
result &lt;- align_topics(lda_models)
```
]

.pull-right[

```r
plot(result)
```

&lt;img src="20240503_files/figure-html/unnamed-chunk-28-1.png" style="display: block; margin: auto auto auto 0;" /&gt;
]

All the simulations discussed today are vignettes in the package. 

---

### Takeaways

* Iterative data structuration is a versatile problem-solving device
* In the topic modeling context, it can be worthwhile to compare `\(K\)`
	- Model comparison deserves attention, not just model selection
* Some relevant links,
	- `alto` documentation: [lasy.github.io/alto](https://lasy.github.io/alto/)
	- `alto` paper: [ https://go.wisc.edu/tify36]( https://go.wisc.edu/tify36)

.pull-left[
&lt;img src="figure/structuration.png" width="200" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="figure/alto_sketches_annotated alignment.png" width="1439" style="display: block; margin: auto;" /&gt;

]

---

### Thank you!

* Collaborators: Laura Symul (UCLouvain), Julia Fukuyama (IU Bloomington)
* Lab Members: Margaret Thairu, Hanying Jiang, Shuchen Yan, Mason Garza, Yuliang Peng, Kaiyan Ma, Kai Cui, and Kobe Uko
* Funding: NIGMS R01GM152744.

---

### Paths

For each `\(v\)`, identify the incoming edge with the highest normalized weight,
`\begin{align*}
  e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
\end{align*}`

* Iterate this process from large to small `\(l\)` to construct a set of distinct paths along the alignment
* The number of unique paths is a useful property of an alignment

&lt;img src="figure/refinement-branches-1.png" width="270" style="display: block; margin: auto;" /&gt;

---

### Paths

For each `\(v\)`, identify the incoming edge with the highest normalized weight,
`\begin{align*}
  e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
\end{align*}`

* Iterate this process from large to small `\(l\)` to construct a set of distinct paths along the alignment
* The number of unique paths is a useful property of an alignment

&lt;img src="figure/refinement-branches-2.png" width="270" style="display: block; margin: auto;" /&gt;

---

### Paths

For each `\(v\)`, identify the incoming edge with the highest normalized weight,
`\begin{align*}
  e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
\end{align*}`

* Iterate this process from large to small `\(l\)` to construct a set of distinct paths along the alignment
* The number of unique paths is a useful property of an alignment

&lt;img src="figure/refinement-branches-3.png" width="270" style="display: block; margin: auto;" /&gt;

---

### Paths

For each `\(v\)`, identify the incoming edge with the highest normalized weight,
`\begin{align*}
  e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
\end{align*}`

* Iterate this process from large to small `\(l\)` to construct a set of distinct paths along the alignment
* The number of unique paths is a useful property of an alignment

&lt;img src="figure/refinement-branches-4.png" width="270" style="display: block; margin: auto;" /&gt;

---

### Paths

For each `\(v\)`, identify the incoming edge with the highest normalized weight,
`\begin{align*}
  e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
\end{align*}`

* Iterate this process from large to small `\(l\)` to construct a set of distinct paths along the alignment
* The number of unique paths is a useful property of an alignment

&lt;img src="figure/refinement-branches-5.png" width="270" style="display: block; margin: auto;" /&gt;

---

### Coherence

The coherence of a topic is defined as its average connectedness to other topics
along the same path,

`\begin{align*}
 c(v) = \frac{1}{|\text{Path}\left(v\right)|} \sum_{v' \in \text{Path}\left(v\right)} \min\left(\win\left(v, v'\right), \wout\left(v, v'\right) \right)
\end{align*}`
  
.pull-left[
* Transient topics (appearing at one `\(K\)` and disappearing at
 another) have low coherence scores
* Consistently recovered topics across choices of `\(K\)` have high coherence
]
 
.pull-right[

]

---

### Refinement

Parent specificity distinguishes two qualitatively different regimes,

* High Refinement: Each topic receives the most mass from a unique parent,
corresponding to a true or "compromise" topic
* Low Refinement: Each topic receives substantial mass from several parents,
each corresponding to an arbitrary split of a true topic

&lt;img src="figure/refinement_diagnostic_example.png" width="350" style="display: block; margin: auto;" /&gt;

---

### Refinement

Parent specificity distinguishes two qualitatively different regimes,

* High Refinement: Each topic receives the most mass from a unique parent,
corresponding to a true or "compromise" topic
* Low Refinement: Each topic receives substantial mass from several parents,
each corresponding to an arbitrary split of a true topic


`\begin{align*}
  r(v)=\frac{\left|V_{m}\right|}{M-m} \sum_{m^{\prime}=m+1}^{M} \sum_{v_{m^{\prime}}^{\prime} \in V_{m^{\prime}}} w_{\mathrm{out}}\left(v, v_{m^{\prime}}^{\prime}\right) w_{\text {in }}\left(v, v_{m^{\prime}}^{\prime}\right)
\end{align*}`
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
