@article{winter2018gut,
  title={Gut microbiome and depression: what we know and what we need to know},
  author={Winter, Gal and Hart, Robert A and Charlesworth, Richard PG and Sharpley, Christopher F},
  journal={Reviews in the Neurosciences},
  volume={29},
  number={6},
  pages={629--643},
  year={2018},
  publisher={De Gruyter}
}

@article{foster2013gut,
  title={Gut--brain axis: how the microbiome influences anxiety and depression},
  author={Foster, Jane A and Neufeld, Karen-Anne McVey},
  journal={Trends in neurosciences},
  volume={36},
  number={5},
  pages={305--312},
  year={2013},
  publisher={Elsevier}
}

@article{Symul2023,
  title = {Sub-communities of the vaginal microbiota in pregnant and non-pregnant women},
  volume = {290},
  ISSN = {1471-2954},
  url = {http://dx.doi.org/10.1098/rspb.2023.1461},
  DOI = {10.1098/rspb.2023.1461},
  number = {2011},
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  publisher = {The Royal Society},
  author = {Symul,  Laura and Jeganathan,  Pratheepa and Costello,  Elizabeth K. and France,  Michael and Bloom,  Seth M. and Kwon,  Douglas S. and Ravel,  Jacques and Relman,  David A. and Holmes,  Susan},
  year = {2023},
  month = nov 
}

@article{peirce2019role,
  title={The role of inflammation and the gut microbiome in depression and anxiety},
  author={Peirce, Jason M and Alvi{\~n}a, Karina},
  journal={Journal of neuroscience research},
  volume={97},
  number={10},
  pages={1223--1241},
  year={2019},
  publisher={Wiley Online Library}
}

@article{dash2015gut,
  title={The gut microbiome and diet in psychiatry: focus on depression},
  author={Dash, Sarah and Clarke, Gerard and Berk, Michael and Jacka, Felice N},
  journal={Current opinion in psychiatry},
  volume={28},
  number={1},
  pages={1--6},
  year={2015},
  publisher={LWW}
}


@article{kerr2021covasim,
  title={Covasim: an agent-based model of COVID-19 dynamics and interventions},
  author={Kerr, Cliff C and Stuart, Robyn M and Mistry, Dina and Abeysuriya, Romesh G and Rosenfeld, Katherine and Hart, Gregory R and N{\'u}{\~n}ez, Rafael C and Cohen, Jamie A and Selvaraj, Prashanth and Hagedorn, Brittany and others},
  journal={PLOS Computational Biology},
  volume={17},
  number={7},
  pages={e1009149},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@techreport{friedman2004multivariate,
  title={On multivariate goodness-of-fit and two-sample testing},
  author={Friedman, Jerome},
  year={2004},
  institution={Citeseer}
}


@article{holmes1993comment,
  title={Comment on “A Model for Studying Display Methods of Statistical Graphics”},
  author={Holmes, Susan},
  journal={Journal of Computational and Graphical Statistics},
  volume={2},
  number={4},
  pages={349--353},
  year={1993},
  publisher={Taylor \& Francis}
}

@article{mallows1982overview,
  title={An overview of techniques of data analysis, emphasizing its exploratory aspects},
  author={Mallows, Colin L and Tukey, John W},
  journal={Some recent advances in statistics},
  volume={33},
  pages={111--172},
  year={1982},
  publisher={Academic Press London}
}

@article{hauser2004interactive,
  title={Interactive analysis of high-dimensional data using visualization},
  author={Hauser, Helwig and Kosara, Robert},
  year={2004},
  publisher={Citeseer}
}

@article{2004-doitrees-revisited,
  title = {DOITrees Revisited: Scalable, Space-Constrained Visualization of Hierarchical Data},
  author = {Jeffrey Heer and Stuart K. Card},
  booktitle = {Advanced Visual Interfaces},
  year = {2004},
  pages = {421--424},
  url = {http://vis.stanford.edu/papers/doitrees-revisited}
}

@article{blei_lda,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
title = {Latent dirichlet allocation},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
journal = {J. Mach. Learn. Res.},
month = {mar},
pages = {993–1022},
numpages = {30}
}
