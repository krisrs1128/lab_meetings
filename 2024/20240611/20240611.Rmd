---
title: "Semisynthetic Simulation for Biological Data Analysis"
author: "Kris Sankaran"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)
library(knitr)
library(RefManageR)
library(tidyverse)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3)
min_theme <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    strip.text = element_text(size = 16),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(min_theme)

# overwrite some default scales in ggplot2
scale_fill_continuous <- function(...) scico::scale_fill_scico(..., palette = "lapaz", direction = -1)
scale_colour_discrete <- function(...) ggplot2::scale_color_brewer(..., palette = "Set2")
scale_x_continuous <- function(...) ggplot2::scale_x_continuous(..., expand = c(0, 0))
scale_y_continuous <- function(...) ggplot2::scale_y_continuous(..., expand = c(0, 0))

BibOptions(
  check.entries = FALSE, 
  bib.style = "authoryear", 
  cite.style = "authoryear", 
  style = "markdown",
  hyperlink = FALSE, 
  dashed = FALSE,
  max.names = 1
)
bib <- ReadBib("references.bib")
set.seed(20240611)
```

<div id="title">
Semisynthetic Simulation for Biological Data Analysis
</div>
<div id="under_title">
Session 1: Marginal Modeling
</div>


<div id="subtitle">
Kris Sankaran <br/>
11 | June | 2024 <br/>
Lab: <a href="https://go.wisc.edu/pgb8nl">go.wisc.edu/pgb8nl</a> <br/>
</div>

<div id="subtitle_right">
Melbourne Integrative Genomics<br/>
Slides: <a href="https://go.wisc.edu/gfj36r">go.wisc.edu/gfj36r</a><br/>
Code: <a href="https://go.wisc.edu/o5sn6w">go.wisc.edu/o5sn6w</a>
</div>

---

### Overall Learning Outcomes

By the end of this course, you will be able to...

1. Describe simulators: What are their building blocks and core properties?

1. Apply simulators: How can we use them to efficiently solve power
analysis and benchmarking problems in biostatistics and computational biology?

1. Compare simulators: What are current trends and their implications?

---

### Tody: Marginal Simulation

<span style="color:#8C1F33">Marginal</span> $\to$ Multivariate $\to$ Integrative

.center[
<img src="figure/integration_types_1a.png" width=600/>
]

---

### Tody: Marginal Simulation

<span style="color:#8C1F33">Marginal</span> $\to$ Multivariate $\to$ Integrative

.center[
<img src="figure/integration_types_1b.png" width=600/>
]

---

### Tody: Marginal Simulation

<span style="color:#8C1F33">Marginal</span> $\to$ Multivariate $\to$ Integrative

.center[
<img src="figure/integration_types_1c.png" width=600/>
]

---

### Today's Learning Outcomes

By the end of this session, you will be able to...

1. Manipulate and interpret `SummarizedExperiment` experiment objects. 
1. Discuss the building blocks of marginal simulation: Probability distributions
and regression models.
1. Design a power analysis for differential testing and accurately communicate its results.
1. Identify areas of your own research where simulation could help better allocate limited resources.

---

### Course Expectations

* Bugs are normal! Resolving them is a skill you will develop.
* Please ask a tutor to help at any point. Don't worry about interrupting.
* We will have breaks and discussions. Get to know the others in the course!

---

class: middle

.center[
## Scientific Context
]

---

### The Microbiome

Imagine a collaboration with researchers who study the human gut microbiome --
the ecosystem of microorganisms that live in the gut. Like ordinary ecology,
they want to know:

.pull-left[
* Who is present?
* How do they interact with one another?
* What are they doing? Which genes are active?
* How does this depend on the environmental context?
]

.pull-right[
```{r, fig.cap = "The microbiome along the gut lining, from Earle et al. 2015.", fig.align = "center", echo = FALSE, out.width = 280}
include_graphics("https://whatislife.stanford.edu/images/spatial.png")
```
]

---

### Study Goals

They are preparing a grant proposal about how community composition is related
to nutrition. The want to compare the microbiomes of malnourished children with
healthy controls.

<img src="figure/nutrition.png"/>

---

### Power Analysis

Since we have the most statistical experience on the team, they ask us:

.center[
<span style="font-family:'Poetsen One'; font-size: 48px;">
How many samples are needed?
</span>

<img src="figure/power_curve.png" width=600px/>

]

<span style="position: absolute; bottom: 20px">
We need to make sure the budget is wisely while ensuring the study isn't underpowered.
</span>

---

### Problem Setup

.pull-left[
This is a differential abundance problem. Which species are more abundant in the
malnourished vs. control groups?
]

.pull-right[
```{r, echo = FALSE, fig.width = 4, fig.height = 5}
library(tidyverse)
library(ggdist)
N <- 10
D <- 20
df <- matrix(rnorm(N * D), N, D)
ix <- sample(1:D, 0.2 * D)
df[1:nrow(df)/2, ix] <- 1 + df[1:nrow(df)/2, 1:2] 
df |>
  as_tibble() |>
  mutate(group = rep(c("malnourished", "control"), each = n() / 2)) |>
  pivot_longer(-group) |>
  mutate(name = str_replace(name, "V", "")) |>
  ggplot() +
    stat_pointinterval(aes(value, name, col = group, fill = group)) +
    labs(x = "Value", y = "Genus")
```
]

---

### Problem Setup

Many methods have been proposed for microbiome differential abundance testing. They account for:

* Potentially extreme sparsity and non-Gaussianity.
* Uneven sequencing depth across samples.
* The large number of tests (and the potential to borrow strength).

This is great news but means we can't just use $t$-test power calculators.

---

### Approach: Simulation

Instead, we simulate. We will simulate experiments and see what our power and
false discovery rate (FDR) look like in those hypothetical datasets.

Abstract power calculation $\to$ Concrete computational experimentation.

.center[
<img src="figure/concrete_power.png" width=800/>
]

---

### Simulation with Templates

* Instead of doing this from scratch, we train a generative
model to existing experimental data ("template data").

* Generative models can _generate_ new, hypothetical samples, not just fit
observed ones `r Citep(bib, "Sankaran2023")`.

.center[
<img src="figure/discriminative_vs_generative.png" width=700/>
]

---

### Simulation with Templates

* Instead of doing this from scratch, we train a generative
model to existing experimental data ("template data").

* Generative models can _generate_ new, hypothetical samples, not just fit
observed ones `r Citep(bib, "Sankaran2023")`.

.center[
<img src="figure/generative_example.png" width=900/>
]

---

### Discussion

Please discuss in groups of 2 - 4: 

* In your own research, what is one place where simulation might help? 
* What template dataset would you use to guide the simulation?

We will debrief responses as a group.

---

class: middle

.center[
## Statistical Approach
]

---

### Approach

The richer our vocabulary for generative models, the better chance we'll have of
finding a realistic simulation mechanism. To this end, we need to familiarize
ourselves with:

1. **Types of data that can serve as templates.**
1. Probability and regression concepts that allow us to fit generative models.

.center[
<img src="figure/summarized_experiment_focus.png" width=150/>
]

---

### Approach

The richer our vocabulary for generative models, the better chance we'll have of
finding a realistic simulation mechanism. To this end, we need to familiarize
ourselves with:

1. Types of data that can serve as templates.
1. **Probability and regression concepts that allow us to fit generative models.**

.center[
  <img src="figure/marginal_goals.png" width=800/>
]

---

### Representing Data

.pull-left[
We can tie together sequencing output, experimental design, and biological
annotation using `SummarizedExperiment` objects. This will let us concisely
learn how `design + biology -> sequencing`. 
]

.pull-right[
<img src="figure/summarized_experiment.svg" width=880/>
]

---

### Code Logistics

Follow along here,

* Code repository: [go.wisc.edu/o5sn6w](https://go.wisc.edu/o5sn6w)
* Live Demo: 

---

### Important Functions

To work with `SummarizedExperiment` objects, we can use:

* `assay`: Returns a matrix whose rows are sequencing features (e.g., genes, taxa, ...) and whose columns are samples.
* `rowData`: Returns a data.frame that annotates each sequencing features.
* `colData`: Returns a data.frame that annotates each sample.


```{r}
library(MIGsim)

data(atlas)
head(colData(atlas))
```

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

This distribution arises when we count the number of successes from a large $N$
trials, each with low probability $p$ of success.

* Flip a very low probability coin a million times.
* Count a million reads' alignment to a rare DNA sequence.

The Poisson parameter $\lambda \approx N p$.

.center[
<img src="figure/poisson_reads.png" width=600/>
]

---

### Count Distributions: Negative Binomial

* This distribution arises when the Poisson parameter is itself random.
* E.g., the coin's probability of heads is no longer constant

$\text{NB}(\mu = 100, \varphi = 5)$

```{r, echo = FALSE, out.width = 700, dpi=400}
data.frame(x = rnbinom(1000, mu = 100, size = 5)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### Count Distributions: Zero-Inflation

Genomic data often have many more zeros than these distributions alone would
capture, so it's common to define zero-inflated versions of the previous
distributions.

$\text{Poi}(\lambda = 10)$ with $\nu = 0.5$ zero inflation:

```{r, echo = FALSE, out.width = 650}
x <- rpois(1000, 10) # generate poissons
z <- rbinom(1000, 1, 0.5) # generates 0/1

data.frame(x = z * x) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### GAMLSS

We will focus on using Generalized Additive Models of Location Shape and Scale
(GAMLSS).  These models allow each parameter of a distribution to depend on
predictors in a smooth way.

```{r, echo = FALSE, out.width = 750}
N <- 1000
x <- runif(N)

f <- spline_fun(knots = seq(0.1, 0.9, 0.2), sd = 0)
theta <- f(x)
y <- rnorm(N, mean = theta[, 1], sd = abs(theta[, 2]))
data.frame(
  x, y,
  mu = theta[, 1], sigma = abs(theta[, 2])
  ) |>
  ggplot() +
  geom_ribbon(aes(x, ymin = mu - 1.9 * sigma, ymax = mu + 1.9 * sigma), fill = "#d3d3d3") +
  geom_line(aes(x, mu), col = "#A2004A", linewidth = 2) +
  geom_point(aes(x, y)) +
  theme_void()
```

---

### Definition

We can use `setup_simulator()` to define a new simulator. This requires:

* The `SummarizedExperiment` template data
* A regression formula relating colData features to the parameters
* The probability model to use (e.g,. Gaussian or Poisson)

```{r}
library(scDesigner)
library(gamboostLSS)
sim <- setup_simulator(exper_ts, ~ group, ~ GaussianLSS())
```

---

### Alteration

We can modify a simulator using the `mutate` command.

```{r}
sim |>
  mutate(1:3, link = ~ group + time)
```

A more realistic example would be to switch to a zero inflated negative binomial
for rare species:

```{r, eval = FALSE}
sim |>
  mutate(any_of(rare_taxa), family = ~ ZINBLSS())
```

---

### Estimation & Sampling


Once a simulator is defined, it can be estimated with `estimate`.

```{r}
sim <- sim |>
  estimate(nu = 0.1) # learning rate = 0.1
```


We can simulate new experiments using `sample`.

```{r}
sample(sim)
```

---

### New Data

Alternatively, we can use a new `colData` object.  This is useful for comparing
sample sizes and experimental designs.

```{r}
new_design <- expand.grid(
  group = c("A", "B"), 
  time = seq(0, 1, 0.1)
)

sample(sim, new_data = new_design)
```

---

class: middle

.center[
## Application
]

---

### Summary

---

### Next Time: Multivariate Simulation

Marginal $\to$ <span style="color:#8C1F33">Multivariate</span> $\to$ Integrative

.center[
<img src="figure/integration_types_2.png" width=600/>
]

---

class: middle

.center[
## Backup Slides
]

---

### Other Distributions

We won't be using the course, but it's worth knowing,

* Gamma Distribution: Continuous, only positive values
* Student's T Distribution: Continuous, allows large outliers
* Tweedie Distribution: Interpolates between count and continuous distributions

---

### What about GANs?

1. These can give good generative models out-of-the-box.

1. The main challenge in practice is supporting manipulation. Most
implementations don't make it easy to draw samples at new experimental designs.

---

### Normalization

The purpose of many normalization and imputation algorithms in genomics is to
_Gaussianize_ the data. It can often be reasonable to apply a Gaussian simulator
to the transformed data `r Citep(bib, c("Law2014-qj", "Jiang2021-jt"))`.

.center[
  <img src="figure/gaussian.svg" width=800/>
]

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\text{Poi}\left(\lambda = 2\right)$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 2)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---
### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\text{Poi}\left(\lambda = 10\right)$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 10)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\text{Poi}\left(\lambda = 100\right)$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 100)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### Incorporating Covariates

1. On their own, the probability distributions we reviewed may not seem like
much, but when we allow them to depend on other features, we can capture a wide
range of distributions.

1. Manipulating the relationship between covariates and response will allow us
to control the simulation more finely.
