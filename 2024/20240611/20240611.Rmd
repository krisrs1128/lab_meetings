---
title: ""
author: "Kris Sankaran"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)
library(knitr)
library(RefManageR)
library(tidyverse)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3)
min_theme <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    strip.text = element_text(size = 16),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(min_theme)

# overwrite some default scales in ggplot2
scale_fill_continuous <- function(...) scico::scale_fill_scico(..., palette = "lapaz", direction = -1)
scale_colour_discrete <- function(...) ggplot2::scale_color_brewer(..., palette = "Set2")
scale_x_continuous <- function(...) ggplot2::scale_x_continuous(..., expand = c(0, 0))
scale_y_continuous <- function(...) ggplot2::scale_y_continuous(..., expand = c(0, 0))

BibOptions(
  check.entries = FALSE, 
  bib.style = "authoryear", 
  cite.style = "authoryear", 
  style = "markdown",
  hyperlink = FALSE, 
  dashed = FALSE,
  max.names = 1
)
bib <- ReadBib("references.bib")
```


<div id="subtitle">
Kris Sankaran <br/>
11 | June | 2024 <br/>
Melbourne Integrative Genomics<br/>
Lab: <a href="https://go.wisc.edu/pgb8nl">go.wisc.edu/pgb8nl</a> <br/>
</div>

<div id="subtitle_right">
<!-- Slides: <a href="https://go.wisc.edu/u10492">go.wisc.edu/u10492</a>  -->
</div>

---

### Overall Learning Outcomes

By the end of this course, you will be able to...

1. Describe the main components of an omics data simulator.
1. Apply simulators to practical power analysis and benchmarking problems.
1. Compare and critique emerging approaches to multi-omics simulation

---

### Course Plan

Marginal $\to$ Joint $\to$ Integrative

(Picture for marginal)

---

### Course Plan

Marginal $\to$ Joint $\to$ Integrative

(Picture for joint)

---

### Course Plan

Marginal $\to$ Joint $\to$ Integrative

(Picture for integrative)

---

### Logistics: Materials

* All the data and code are available here:
* You can follow-along my coding session here: 

---

### Logistics: Communication

* It is normal to run into bugs! Part of the learning process is knowing how to analyze and resolve them.
* Please ask a tutor to help resolve problems at any point -- no need to wait for a pause in lecture.
* We will have breaks and group discussions -- get to know the others in the course!

---

### Learning Outcomes: Session 1

By the end of this session, you will be able to...

1. Design and implement a power analysis for a differential expression analysis
2. Discuss the building blocks of marginal simulation: Classes of distributions (Poisson, NB, gaussian), types of marginal regression models.
3. Distinguish between types of simulation: De Novo, Resampling, and Semisynthetic
4. Identify areas of your own research where simulation could help better allocate limited resources

---
class: middle

.center[
## Introduction
]

---

### Story: The Grant Proposal

How many samples should your team gather? How many from healthy vs. disease?

* It's important that that study isn't underpowered
* We want to use the budget as wisely as possible

---

### Story: The Grant Proposal

You look at one of their past grant proposals, and they just used a $t$-test
calculator...

You know that the team is interested in differential analysis, so you decide
you'll compare a few microbiome differential analysis methods on simulated data.

---

### Approach: Simulation

By simulating data, you can,

* Control the ground truth associations $\to$ Compute ground truth false discovery rates (FDR) and power
* Compare power as a function of sample size, class balance, and testing strategy

---

### Foundation: The Atlas Study

You decide that the most similar dataset to your proposal is the dataset in `r Citep(bib, "")`.

---

### Foundation: The Atlas Study

Our goal for today will be to simulate data that look similar to that data, but
where we can control the ground truth associations and experimental design.

---

### Simulator Taxonomy

There are three main types of simulator.

* De Novo: Define the generative mechanism without referring to any real data.
* Resampling: Take a real dataset and perturb it in a systematic way.
* Semisynthetic: Fit a controllable, generative model to a dataset.

---

### De Novo Simulators

Example: (maybe draw pictures for each of these examples)

\begin{align}
x_{i} \leftarrow \begin{cases}
\mathcal{N}\left(\mu_{0}, \Sigma \right) \text{ for Control} \\
\mathcal{N}\left(\mu_{1}, \Sigma \right) \text{ for Treatment}
\end{cases}
\end{align}

.pull-left[
Advantages: Fully transparent mechanism.
]

.pull-right[
Disadvantages: No point of reference. Hard to evaluate how close it is to real
data -- can result in lots of wasted time tinkering without clear sense of
progress.
]

---

### Resampling Simulators

Example: Let $z_i$ be a sample from the real dataset. Then, simulate new samples:

\begin{align}
y_{i} \leftarrow \begin{cases} 
z_i \text{ for Control} \\
\exp{\beta} z_i \text{ for Treatment}
\end{cases}
\end{align}

.pull-left[

Advantages: Fully nonparametric, can match arbitrarily complex data distributions.
]

.pull-right[
Disadvantages: Can be difficult to control. For example, how to remove effect
from one covariate but not another?
]

---

### Semisynthetic Simulators

Example: Fit a model,
\begin{align*}
z_{i} = m_{i}^{T} \beta + \epsilon_{i}
\end{align*}
given previously observed samples $z_i$ and design $m_{i}$.

Given target design $m_i$, simulate new samples:
\begin{align*}
y_{i} \leftarrow m_{i} \hat{\beta} + \epsilon_{i}
\end{align}

.pull-left[
Advantages: Compromise between De Novo and Resampling based simulators -- both realistic and controllable.
]

.pull-right[
Disadvantages: Fitting high-quality generative models can be challenging.
]

---

### Discussion

Discuss in groups of 2 - 4: 

* In your own research, what is one situation where simulation might be helpful? 
* Pick one of the simulator types and explain how it might be applied.

Google Doc: 

---

class: middle

.center[
## Marginal Simulation - Concepts
]

---

### Approach

The richer our vocabulary for generative models, the better chance we'll have of
finding a realistic simulation mechanism. To this end, we need to familiarize
ourselves with:

1. A few types of probability distributions -- both count and continuous.
1. Ways of linking these distributions with external information (e.g., disease status)

---

### Count Distributions: Poisson

This distribution arises when we count the number of successes from many trials
when the probability of success is very low.

* The number of heads after flipping a biased $p = 0.0001$ coin a $N = $ million times
* In a library with 10 million reads, the number that align to the sequence ATCCCTGGACCG...

```{r}
library(tidyverse)
data.frame(x = rpois(1000, 10)) |>
  ggplot() +
  geom_histogram(aes(x), bins = 100)
```

---

### Count Distributions: Negative Binomial

This distribution arises when the Poisson's mean parameter is itself random.

* The number of heads after flipping many biased coins $N = $ million times, where the coins have probability $p = 0.000215, 0.001313, 0.000841, \dots$
* The number of reads aligning to a sequence across many runs where temperature might influence binding

This additional variability induces _overdispersion_ relative to the Poisson.

```{r}
data.frame(x = rnbinom(1000, 1, .1)) |>
  ggplot() +
  geom_histogram(aes(x), bins = 200)
```

---

### Count Distributions: Zero-Inflation

Genomic data often have many more zeros than these distributions alone would
capture. For this reason, it's common to define zero-inflated versions of the
previous distributions:

```{r}
x <- rpois(1000, 10) # generate poissons
z <- rbinom(1000, 1, 0.5) # generates 0/1
z * x # zero inflated poisson
```

---

### Continuous Distributions: Gaussian

The purpose of many normalization and imputation algorithms in genomics is to
_Gaussianize_ the data. It can often be reasonable to apply a Gaussian simulator
to the transformed data.

---

### Other Distributions

We won't be using the course, but it's worth knowing,

* Gamma Distribution: Continuous, only positive values
* Student's T Distribution: Continuous, allows large outliers
* Tweedie Distribution: Interpolates between count and continuous distributions

---

### Incorporating Covariates

On their own, these distributions may not seem like much, but when we allow them
to depend on other features, we can capture a wide range of distributions.

---

### GAMLSS

The main idea is to allow each parameter of a distribution to depend on
predictors in a smooth way.

```{r}
N <- 1000
x <- runif(N)

f <- multimedia:::spline_fun(knots = seq(0.1, 0.9, 0.2), sd = 0)
theta <- f(x)
y <- rnorm(N, mean = theta[, 1], sd = abs(theta[, 2]))
plot(x, y)
```

(maybe make this a gganimate animation?)

---

## Marginal Simulation Practice

---

### Definition

We will usually use `setup_simulator()` to define a new simulator. This requires:

* The `SummarizedExperiment` template data
* A regression formula relating colData features to the parameters
* The probability model to use (e.g,. Gaussian or Poisson)

```{r}
sim <- setup_simulator(exper, ~ group, ~ GaussianLSS())
```

---

### Definition

```{r}
sim
```

---

### Alteration

We can modify a simulator using the `mutate` command. 

Add a time effect for three features:

```{r}
sim |>
  mutate(1:3, link = ~ group + time)
```

Change to zero inflated negative binomial for features features within a vector:

```{r, eval = FALSE}
sim |>
  mutate(any_of(rare_taxa), family = ~ ZINBLSS())
```

---

### Estimation

Once a simulator is defined, it can be estimated using the `estimate` function.
It can refer to any parameters used in the original LSS estimation package.

```{r, eval = FALSE}
sim <- sim |>
  estimate(nu = 0.1) # learning rate = 0.1
```

---

### Sampling

Once we've estimated a simulator, we can sample from it using the `sample`
command. It returns a `SummarizedExperiment` with the same dimensions as the
original data.

```{r}
sample(sim)
```

---

### Sampling

Alternatively, we can create a new `colData` design and ask to sample at that
configuration. This is useful for comparing sample sizes and experimental
designs.

```{r}
new_design <- expand.grid(
  group = c("A", "B"), 
  time = seq(0, 1, 0.1)
)

sample(sim, new_data = new_design)
```

---

### Exercise

---

### Application

---