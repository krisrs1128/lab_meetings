---
title: "Semisynthetic Simulation for Biological Data Analysis"
author: "Kris Sankaran"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(MASS)
library(knitr)
library(RefManageR)
library(tidyverse)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3)
min_theme <- theme_minimal() + 
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#f7f7f7"),
    panel.border = element_rect(fill = NA, color = "#0c0c0c", size = 0.6),
    axis.text = element_text(size = 14),
    strip.text = element_text(size = 16),
    axis.title = element_text(size = 16),
    legend.position = "bottom"
  )
theme_set(min_theme)

# overwrite some default scales in ggplot2
scale_fill_continuous <- function(...) scico::scale_fill_scico(..., palette = "lapaz", direction = -1)
scale_colour_discrete <- function(...) ggplot2::scale_color_brewer(..., palette = "Set2")
scale_x_continuous <- function(...) ggplot2::scale_x_continuous(..., expand = c(0, 0))
scale_y_continuous <- function(...) ggplot2::scale_y_continuous(..., expand = c(0, 0))

BibOptions(
  check.entries = FALSE, 
  bib.style = "authoryear", 
  cite.style = "authoryear", 
  style = "markdown",
  hyperlink = FALSE, 
  dashed = FALSE,
  max.names = 1
)
bib <- ReadBib("references.bib")
```

<div id="title">
Semisynthetic Simulation for Biological Data Analysis
</div>
<div id="under_title">
Session 1: Marginal Modeling
</div>


<div id="subtitle">
Kris Sankaran <br/>
11 | June | 2024 <br/>
Melbourne Integrative Genomics<br/>
Lab: <a href="https://go.wisc.edu/pgb8nl">go.wisc.edu/pgb8nl</a> <br/>
</div>

<div id="subtitle_right">
<!-- Slides: <a href="https://go.wisc.edu/u10492">go.wisc.edu/u10492</a>  -->
</div>

---

### Overall Learning Outcomes

By the end of this course, you will be able to...

1. Describe the main components of an omics data simulator.
1. Apply simulators to practical power analysis and benchmarking problems.
1. Compare and critique emerging approaches to multi-omics simulation

---

### Course Plan

<span style="color:#8C1F33">Marginal</span> $\to$ Joint $\to$ Integrative

.center[
<img src="figure/integration_types_1a.png" width=600/>
]

---

### Course Plan

<span style="color:#8C1F33">Marginal</span> $\to$ Joint $\to$ Integrative

.center[
<img src="figure/integration_types_1b.png" width=600/>
]

---

### Course Plan

<span style="color:#8C1F33">Marginal</span> $\to$ Joint $\to$ Integrative

.center[
<img src="figure/integration_types_1c.png" width=600/>
]

---

### Course Plan

Marginal $\to$ <span style="color:#8C1F33">Joint</span> $\to$ Integrative

.center[
<img src="figure/integration_types_2.png" width=600/>
]

---

### Course Plan

Marginal $\to$ Joint $\to$ <span style="color:#8C1F33">Integrative</span>

.center[
<img src="figure/integration_types_3.png" width=600/>
]

---

### Logistics: Materials

You should be able to follow along by referring to these resources:

* Code repository:
* Live Demo: 

---

### Logistics: Communication

* Bugs are normal! Resolving them is a skill you will develop.
* Please ask a tutor to help at any point. Don't worry about interrupting.
* We will have breaks and discussions. Get to know the others in the course!

---

### Learning Outcomes: Session 1

By the end of this session, you will be able to...

1. Design and interpret a power analysis for differential abundance testing.
1. Discuss the building blocks of marginal simulation: Classes of distributions (Poisson, NB, gaussian), types of marginal regression models.
1. Identify areas of your own research where simulation could help better allocate limited resources.

---
class: middle

.center[
## Introduction
]

---

### Microbiome Context

Imagine a collaboration with researchers who study the human gut microbiome --
the ecosystem of microorganisms that live in the gut. Like ordinary ecology,
they want to know:

.pull-left[
* Who is present?
* How do they interact with one another?
* What are they doing? Which genes are active?
* How does this depend on the environmental context?
]

.pull-right[
```{r, fig.cap = "The microbiome along the gut lining, from Earle et al. 2015.", fig.align = "center", echo = FALSE, out.width = 280}
include_graphics("https://whatislife.stanford.edu/images/spatial.png")
```
]

---

### Study Goals

They are preparing a grant proposal about how community composition is related
to nutrition. The want to compare the microbiomes of malnourished children with
healthy controls.

<img src="figure/nutrition.png"/>

---

### Power Analysis

Since we have the most statistical experience on the team, they ask us:

.center[
<span style="font-family:'Poetsen One'; font-size: 48px;">
How many samples are needed?
</span>

<img src="figure/power_curve.png" width=600px/>

]

<span style="position: absolute; bottom: 20px">
We need to make sure the budget is wisely while ensuring the study isn't underpowered.
</span>

---

### Problem Setup

.pull-left[
This is a differential abundance problem. Which species are more abundant in the
malnourished vs. control groups?
]

.pull-right[
```{r, echo = FALSE, fig.width = 4, fig.height = 5}
library(tidyverse)
library(ggdist)
N <- 10
D <- 20
df <- matrix(rnorm(N * D), N, D)
ix <- sample(1:D, 0.2 * D)
df[1:nrow(df)/2, ix] <- 1 + df[1:nrow(df)/2, 1:2] 
df |>
  as_tibble() |>
  mutate(group = rep(c("malnourished", "control"), each = n() / 2)) |>
  pivot_longer(-group) |>
  mutate(name = str_replace(name, "V", "")) |>
  ggplot() +
    stat_pointinterval(aes(value, name, col = group, fill = group)) +
    labs(x = "Value", y = "Genus")
```
]

---

### Problem Setup

Many methods have been proposed for microbiome differential abundance testing. They account for:

* Potentially extreme sparsity and non-Gaussianity.
* Uneven sequencing depth across samples.
* The large number of tests (and the potential to borrow strength).

This is good news but also means we can't just use $t$-test power calculators.

---

### Approach: Simulation

Instead, we simulate. We will simulate experiments and see what our power and
false discovery rate (FDR) look like in those hypothetical datasets.

Abstract power calculation $\to$ Concrete computational experimentation.

.center[
<img src="figure/concrete_power.png" width=800/>
]

---

### Simulation using Templates

* The challenge is making realistic simulated data.

* Instead of doing this from scratch, we train a generative
model to existing experimental data ("template data").


---

### Generative Models

Generative models can _generate_ new, hypothetical samples, not just fit
observed ones `r Citep(bib, "Sankaran2023")`.

.center[
<img src="figure/discriminative_vs_generative.png" width=900/>
]

---

### Generative Models

Generative models can _generate_ new, hypothetical samples, not just fit
observed ones `r Citep(bib, "Sankaran2023")`.

.center[
<img src="figure/generative_example.png" width=900/>
]

---

### Foundation: The Atlas Study

* We decide that the most similar dataset to our proposal is the dataset in `r Citep(bib, "Lahti2014")`.

* Our goal today will be to simulate data that look similar to that data, but where we can control the ground truth associations and experimental design.

---

### Discussion

Please discuss in groups of 2 - 4: 

* In your own research, what is one situation where simulation might be helpful? 
* What would be a template dataset you could use to guide your simulation?

We will debrief responses as a group.

---

class: middle

.center[
## Marginal Simulation - Concepts
]

---

### Approach

The richer our vocabulary for generative models, the better chance we'll have of
finding a realistic simulation mechanism. To this end, we need to familiarize
ourselves with:

1. A few types of probability distributions -- both count and continuous.
1. Ways of linking these distributions with external information (e.g., disease status)

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

This distribution arises when we count the number of successes from a large $N$
trials, each with low probability $p$ of success.

* Flip a very low probability coin a million times.
* Count a million reads' alignment to a rare DNA sequence.

The Poisson parameter $\lambda \approx N p$.

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\lambda = 2$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 2)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---
### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\lambda = 10$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 10)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### Count Distributions: $\text{Poi}\left(\lambda\right)$

$\lambda = 100$

```{r, out.width = 800, echo = FALSE}
library(ggplot2)
data.frame(x = rpois(1000, 100)) |>
  group_by(x) |>
  dplyr::count() |>
  ggplot() +
  geom_col(aes(x, n))
```

---

### Count Distributions: Negative Binomial

This distribution arises when the Poisson's mean parameter is itself random.

* The number of heads after flipping many biased coins $N = $ million times, where the coins have probability $p = 0.000215, 0.001313, 0.000841, \dots$
* The number of reads aligning to a sequence across many runs where temperature might influence binding

This additional variability induces _overdispersion_ relative to the Poisson.

```{r}
data.frame(x = rnbinom(1000, 1, .1)) |>
  ggplot() +
  geom_histogram(aes(x), bins = 200)
```

---

### Count Distributions: Zero-Inflation

Genomic data often have many more zeros than these distributions alone would
capture. For this reason, it's common to define zero-inflated versions of the
previous distributions:

```{r}
x <- rpois(1000, 10) # generate poissons
z <- rbinom(1000, 1, 0.5) # generates 0/1
z * x # zero inflated poisson
```

---

### Continuous Distributions: Gaussian

The purpose of many normalization and imputation algorithms in genomics is to
_Gaussianize_ the data. It can often be reasonable to apply a Gaussian simulator
to the transformed data `r Citep(bib, "Law2014-qj")`.

---

### Other Distributions

We won't be using the course, but it's worth knowing,

* Gamma Distribution: Continuous, only positive values
* Student's T Distribution: Continuous, allows large outliers
* Tweedie Distribution: Interpolates between count and continuous distributions

---

### Incorporating Covariates

On their own, these distributions may not seem like much, but when we allow them
to depend on other features, we can capture a wide range of distributions.

---

### GAMLSS

The main idea is to allow each parameter of a distribution to depend on
predictors in a smooth way.

```{r, echo = FALSE, out.width = 900}
N <- 1000
x <- runif(N)

f <- multimedia:::spline_fun(knots = seq(0.1, 0.9, 0.2), sd = 0)
theta <- f(x)
y <- rnorm(N, mean = theta[, 1], sd = abs(theta[, 2]))
data.frame(x, y) |>
  ggplot() +
  geom_point(aes(x, y))
```

(maybe make this a gganimate animation?)

---

## Marginal Simulation - Practice

---

### Aside: SummarizedExperiment

Estimation and simulation in `scDesigner` will work at the level of
`SummarizedExperiment` objects.

.pull-left[
These containers have three slots:
* `assay`: Feature-by-sample measurements
* `rowData`: Feature annotation
* `colData`: Sample annotation
]

.pull-right[
<img src="figure/summarized_experiment.svg" width=800/>
]


### Aside: SummarizedExperiment

```{r}
atlas <- readRDS("data/atlas.rds")
atlas
```

```{r, echo = FALSE}
exper_ts <- readRDS("data/exper_ts.rds")
```

---

### Definition

We can use `setup_simulator()` to define a new simulator. This requires:

* The `SummarizedExperiment` template data
* A regression formula relating colData features to the parameters
* The probability model to use (e.g,. Gaussian or Poisson)

```{r}
exper_ts
```

---

### Definition

We can use `setup_simulator()` to define a new simulator. This requires:

* The `SummarizedExperiment` template data
* A regression formula relating colData features to the parameters
* The probability model to use (e.g,. Gaussian or Poisson)

```{r}
colData(exper_ts)
```

---

### Definition

We can use `setup_simulator()` to define a new simulator. This requires:

* The `SummarizedExperiment` template data
* A regression formula relating colData features to the parameters
* The probability model to use (e.g,. Gaussian or Poisson)

```{r}
library(scDesigner)
library(gamboostLSS)
sim <- setup_simulator(exper_ts, ~ group, ~ GaussianLSS())
```

---

### Definition

```{r}
sim
```

---

### Alteration

We can modify a simulator using the `mutate` command.  This adds temporal
dependence.

```{r}
sim |>
  mutate(1:3, link = ~ group + time)
```

A more realistic example would be to switch to a zero inflated negative binomial
for rare species:

```{r, eval = FALSE}
sim |>
  mutate(any_of(rare_taxa), family = ~ ZINBLSS())
```

---

### Estimation


.pull-left[
Once a simulator is defined, it can be estimated using the `estimate` function.
It can refer to any parameters used in the original LSS estimation package.

```{r}
sim <- sim |>
  estimate(nu = 0.1) # learning rate = 0.1
```
]

---

### Sampling

Once we've estimated a simulator, we can sample from it using the `sample`
command. It returns a `SummarizedExperiment` with the same dimensions as the
original data.

```{r}
sample(sim)
```

---

### Sampling

Alternatively, we can use a new `colData` object.  This is useful for comparing
sample sizes and experimental designs.

```{r}
new_design <- expand.grid(
  group = c("A", "B"), 
  time = seq(0, 1, 0.1)
)

sample(sim, new_data = new_design)
```

---

### Exercise

---

### Application
