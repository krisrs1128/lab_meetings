\documentclass{beamer}
\input{preamble}
%Information to be included in the title page:
\title{Multi-resolution Analysis of Count Data using Topic Alignment}
\author{Kris Sankaran}
\date{August 20, 2021}
%\graphicspath{{figure}}

\begin{document}

\frame{\titlepage}

\begin{frame}
  \frametitle{Preface}

  45 minutes: Topic Alignment
  \begin{itemize}
    \item How to turn this into a more widely-shareable talk?
    \item Which types of audiences to have in mind?
  \end{itemize}

  15 minutes: Soil microbiome study
  \begin{itemize}
  \item Data analysis suggestions?
  \end{itemize}
\end{frame}

\section{Topic Alignment}

\begin{frame}
  \frametitle{Scientific Problem}
  \begin{itemize}
  \item We are interested in what constitutes a healthy vaginal microbiome
  \item We want to understand risk factors that can be determined by analyzing
  \item To this end, a study has collected longitudinal microbiome data on X
  women over Y - Z weeks using 16S sequencing
  the microbiome
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Data Analysis Problem}
\begin{itemize}
  \item We can assume that the raw sequencing reads have been passed through a
  pipeline that results in an $N$ samples by $D$ Amplicon Sequence Variant (ASV)
  count matrix
  \item We have a variety of characteristics about each mother, including
  whether or not they had a preterm birth
  \item The main sources of complexity are,
  \begin{itemize}
    \item Not all the known relevant bacterial species are known in advance
    \item There might be interaction effects that lead to improved / worsened
    outcomes
    \item $D$ is large
  \end{itemize}
\end{itemize}
\end{frame}
\begin{frame}
  \frametitle{Standard Approaches}
  \begin{itemize}
    \item Multiple Testing: Return a list of species that are strongly
    associated with preterm birth
    \item Hierarchical Clustering: Return a tree describing groups of species
    that tend to have similar abundance levels across samples
    \item Principal Component Analysis: Return a projection that shows how
    changes in species signature relates to variation in sample characteristics
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Why are these methods useful?}
    These outputs are cognitive artifacts that support scientific reasoning.
    Human working memory is limited, and these methods provide,
    \begin{itemize}
      \item A compressed representation that is easier to reason about
      (Clustering and PCA)
      \item Guidance of attention to details of interest (Multiple testing)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Key Tasks}
  To solve problems like those that the VMRC cares about, it's necessary to
  assemble subtle clues into coherent, high-level theories. This requires both,
  \begin{itemize}
    \item Critical evaluation: What assumptions are actually being made about
    the data? It helps to have an explicit model.
    \item Navigation: We have a range of both simple and complex models easily
    available, but navigating the complexity-interpretability trade-offs between
    them is difficult
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Relevant Literature}
  \begin{itemize}
    \item Cluster comparison:
    \item Hierarchical Topic Models:
    \item Factored Topic Models:
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Main Idea}
  We will fit an ensemble of generative models, of varying levels of complexity,
  and each of which can be critically evaluated. Then, we will build a compact
  representation that streamlines navigation across them.
  (Provide a figure)
\end{frame}

\subsection{Methodology}

\begin{frame}
  \frametitle{Topic Models}
  On popular topic model is Latent Dirichlet Allocation (LDA), which supposes
  that each $x_{i}$ is drawn independently according to,
  \begin{align*}
  x_i \vert \gamma_i &\sim \Mult\left(n_{i}, B\gamma_{i}\right) \\
  \gamma_{i} &\sim \Dir\left(\lambda_{\gamma} 1_{K}\right)
  \end{align*}
  where the columns $\beta_{k}$ of $B \in \simplex^{D}$ lie in the $D$
  dimensional simplex and are themselves drawn independently from,
  \begin{align*}
  \beta_{k} \sim \Dir\left(\lambda_{\beta} 1_{D}\right).
\end{align*}
  We will vertically stack the $N$ $\gamma_i$'s into an $N \times K$ matrix
  $\Gamma$.
\end{frame}

\begin{frame}
  \frametitle{Interpretation}
Topic models are well-suited to dimensionality reduction of count data. The
estimated parameters have the following interpretation,
\begin{itemize}
  \item $\Gamma \in \Delta_{K}^{N}$: Per-document memberships across $K$ topics.
  \item $B \in \Delta_{V}^{K}$: Per topic distributions over $V$ words.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Alignment as a Graph}
  We view an alignment as a graph across the ensemble. Index models by $m$ and
  topics by $k$. Then,

  \begin{itemize}
    \item Nodes $V$ corresponds to topics, parameterized by $\{\beta^m_{k},
    \gamma^m_{ik}\}$.
    \item Edges $E$ are placed between topics from neighboring models ($K$ vs.
    $K + 1$ topics)
    \item Weights $W$ encode the similarity between topics.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Notation}
  This graph-based view provides a convenient notation,
  \begin{itemize}
  \item $m\left(v\right)$ is the model for node $v$
  \item $k\left(v\right)$ is the topic for node $v$
  \item $\Gamma\left(v\right) := \left(\gamma_{i
  v\left(k\right)}^m\left(k\right)\right) \in \reals^n_{+}$ is the vector of
  mixed memberships for topic $v$
  \item $\beta\left(v\right) := \beta_{k}^m \in \simplex^{D}$ is the
  corresponding topic distribution
  \item $e = \left(v, v'\right)$ is an edge linking topics $v$ and $v'$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{$W$ via the product method}
How should we estimate the weights? One idea is to use
\begin{align*}
w\left(e\right) = \Gamma\left(v\right)^T\Gamma\left(v'\right)
\end{align*}
\end{frame}

\begin{frame}
  \frametitle{$W$ via the transport method}
  Let $V_p$ and $V_q$ be two subsets of topics within the graph.
  \begin{itemize}
    \item Let the total ``mass'' of $V_p$ be $p =
    \left\{\Gamma\left(v\right)^T 1 : v \in V_{p}\right\}$. Define $q$ similarly.
    \item Define the transport cost $C\left(v, v^\prime\right) :=
    JSD\left(\beta\left(v\right), \beta\left(v^\prime\right)\right)$, the
    Jensen-Shannon divergence between the pair of topic distributions.
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{$W$ via the transport method}
The weights $W$ can than be estimated by solving the optimal transport problem,
\begin{align*}
&\min_{W \in \mathcal{U}\left(p, q\right)} \left<C,W\right> \\
\mathcal{U}\left(p, q\right) := &\{W\in \reals^{\absarg{p} \times \absarg{q}}_{+} : W 1_{\absarg{q}} = p \text{ and } W^{T} 1_{\absarg{p}^\prime} = q\}.
\end{align*}
\end{frame}

\begin{frame}
  \frametitle{Summaries}
  \begin{itemize}
    \item Representing the models by an alignment suggests a few summary measures
    \item These summaries help measure topic quality
    \item They can also be used to diagnose model mis-specification
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Key Topics}
  For each $v$, identify the incoming edge with the highest normalized weight,
  \begin{align*}
    e^\ast\left(v\right) = \arg \max_{e : \text{target}\left(e\right) = v} \tilde{w}_{\text{out}}\left(e\right) + \tilde{w}_{\text{in}}\left(e\right).
  \end{align*}
  \begin{itemize}
    \item Any node that is a source node for one such edge is called a key topic
    \item This filters away nodes that don't have definitive descendants
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Refinement}
  Suppose there are actually $K_0$ topics in the data. If we fit a model with
  $K$ topics, then
  \begin{itemize}
    \item $K < K_0$: True topics are merged together into ``compromise'' topics
    \item $K > K_0$: True topics are arbitrarily split
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Refinement}
  A consequence is that the parent specificity differs between these
  regimes,
  \begin{itemize}
    \item $K < K_0$: Each topic receives most mass from a unique parent,
    corresponding to a true or ``compromise'' topic
    \item $K > K_0$: Each topic receives substantial mass from several parents,
    each corresponding to an arbitrary split of a true topic
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Coherence}
  The coherence of a topic is defined as its average connectedness to other
  topics along the same branch,
  \begin{align*}
    c(v) = \frac{1}{|M'|} \sum_{m' \in M'} \sum_{v' \in V_{m'}} \min\left(\win\left(v, v'\right), \wout\left(v, v'\right) \right)
  \end{align*}
  \begin{itemize}
    \item Topics that are transient (appearing at one $K$ and disappearing at
    another) have low coherence scores
    \item Topics that are consistently recovered across choices of $K$ have high
    coherence
  \end{itemize}

\end{frame}

\subsection{Simulation}
\begin{frame}
  \frametitle{True LDA Model}
  A sanity check is compute the alignment of data that are in fact generated by an
  LDA model (true $K = 5$).
  \begin{itemize}
  \item $N = 250, D = 1000, \lambda_{\gamma} = 0.5, \lambda_{\beta} = 0.1$
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Summaries}
  Each of the summary measures suggest that the true $K$ is 5.
\end{frame}

\begin{frame}
  \frametitle{LDA with background variation}
  What happens when the LDA model is mis-specified? Consider the following
  generative mechanism,
  \begin{align*}
x_{i} \vert \*B, \gamma_{i}, \nu_i &\sim \Mult\left(x_{i} ; N_{i}, \alpha \*B\gamma_{i} + \left(1 - \alpha\right)\nu_i\right) \\
\nu_{i} &\sim \Dir\left(\lambda_{\nu}\right) \\
\gamma_i &\sim \Dir\left(\lambda_{\gamma}\right) \\
\beta_{k} &\sim \Dir\left(\lambda_{\beta}\right),
\end{align*}
where $\*B$ stacks the $\beta_k$ rowwise.
\end{frame}

\begin{frame}
  \frametitle{Result}
  The alignment structure is sensitive to changes in $\alpha$ and fragments when
  LDA structure is not present.
\end{frame}

\begin{frame}
  \frametitle{Summaries}
  This structure is consistent across simulation runs, and the summary measures
  quantify the deterioration of topics.
\end{frame}

\begin{frame}
  \frametitle{Strain switching}
  Our final simulation mimics the strain switching problem.
  \begin{itemize}
    \item Small subsets of species switch between two otherwise similar topics
    \item Multiple resolutions are required to detect the difference
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Mechanism}
We first construct a set of ``perturbed'' topics. Then, for each sample $i$, we draw
\begin{align*}
\beta_{k}^{i} &\sim \Unif\left(\left\{\tilde{\beta}_{k}^{1}, \dots, \tilde{\beta}_{k}^{R}\right\}\right)
\end{align*}
stack the results into a $K$ column matrix $B^{i}$, and then draw,
\begin{align}
x_{i} &\sim \Mult\left(n_{i}, B^{i}\gamma_{i}\right)
\end{align}
as in standard LDA.
\end{frame}

\begin{frame}
  \frametitle{Results}
  \begin{itemize}
    \item At smaller $K$, we recognize the main community structure, but don't see strain switching
    \item At larger $K$, we are able to recognize instances of switching
  \end{itemize}
\end{frame}

\subsection{Data Analysis}

\section{Analyzing THOR (The Hitchhikers of the Rhizosphere)}

\end{document}
