---
title: "Selective Inference in Computational Genomics"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    fig_caption: true
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title
background-image: url("figure/selective-cover.png")
background-size: cover


```{r, echo = FALSE, warnings = FALSE, message = FALSE}
library(RefManageR)
library(knitr)
library(tidyverse)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3, eval = TRUE)
opts_knit$set(eval.after = "fig.cap")

BibOptions(cite.style = "numeric")
bib <- ReadBib("references.bib")
```

.pull-left[
<div id="title">
Selective Inference for Computational Genomics
</div>
<div id="subtitle">
Computational Genomics Summer Institute <br/>
Kris Sankaran <br/>
14 | July | 2023 <br/>
https://github.io/krisrs1128/LSLab
</div>
]

---

### Learning Objectives

You will be able to help collaborators accurately resolve scientific issues by adapting high-power methods from selective inference.

By the end of this talk, you will be able to:

1. Discuss the role of selective inference abstractions in computational genomics settings.
1. Interpret $p$-value histograms and explain how they motivate the Benjamini-Hochberg procedure.
1. Improve power in large scale inference by focusing attention on the most promising contexts.
1. Diagnose miscalibration in large scale inference and apply data splitting to address it.

---

### Large Scale Inference

Notation
  * Hypotheses of interest: $H_{1}, \dots, H_{M}$
  * Associated $p$-values: $p_{1}, \dots, p_{M}$.

Goal: Reject as many non-null hypotheses as possible while controlling the False Discovery Rate, $\mathbb{E}\left[\left\|\frac{\mathrm{False Positives}\right\|}{\left\|\mathrm{Rejections}\right\|}].

---

### Examples

Whenever the signal is subtle, hypothesis testing is crucial.

* Cancer: Is elevated immune cell expression of gene $m$ associated with improved survival rates?
* Microbiome: Is taxon $m$ associated with development of Type 1 diabetes?
* Epigenetics: Is SNP $i$ associated with histone marker $j$? Each $i-j$ pairs defines on test $H_{m}$.

--- 

### $p$-value histogram

* Under the null, the $p$-values follow a uniform distribution. 
* The spike near 0 are likely from the alternative
* $\pi_{0}$ denotes the true proportion of nulls

[ Image of p-value histogram ]

---

### $p$-value histogram

* Under the null, the $p$-values follow a uniform distribution. 
* The spike near 0 are likely from the alternative
* $\pi_{0}$ denotes the true proportion of nulls

[ show some with larger or smaller p-value histograms ]

---

### Benjamini-Hochberg

The BH procedure selects hypotheses in a way that controls the FDR at level $q$.

1. Sort the p-values: $p_{(1)} \leq p_{(2}) \leq \dots \leq p_{(m)}$
1. Find the largest $i$ such that $p_{(i)} leq \frac{i q}{m}$
1. Reject hypotheses associated with $p_{(1)} \leq \dots \leq p_{(i)}$ 

---

### Why?

At any threshold $t$, estimate

\begin{align*}
\hat{\text{FDR}}\left(t\right) &= \frac{\mathrm{Blue}}{\mathrm{Blue} + \mathrm{Purple}}
\end{align*}

[Figure of the p-values with the areas shaded in]

---

### Why?

Let $R\left(t\right)$ be the number of rejected hypotheses at threshold $t$. Then,

\begin{align*}
\hat{\text{FDR}}\left(t\right) &= \frac{\pi_{0}mt}{R\left(t\right)}
\end{align*}

---

### Why?

Maximize the number of rejections while limiting false discoveries.

.pull-left[
Optimize:
\begin{align*}
\text{maximize } &R\left(t\right) \\
\text{subject to } &\hat{\text{FDR}} \leq q
\end{align*}
]

---

### Why?

Larger thresholds let more hypotheses through.

.pull-left[
Optimize:
\begin{align*}
\text{maximize } & t \\
\text{subject to } &\hat{\text{FDR}} \leq q
\end{align*}
]

---

### Why?

Look for the largest $p$-value satisfying this inequality.

.pull-left[
Optimize:
\begin{align*}
\text{maximize } &R\left(t\right) \\
\text{subject to } &\hat{\text{FDR}} \leq q
\end{align*}
]

.pull-right[
If we substitute $t = p_{(i)}$, then

\begin{align*}
\frac{\pi_{0}m p_{(i)}}{i} &\leq q \\
&\implies p_{(i)} \leq \frac{i q}{\pi_{0} m}
\end{align*}
]

---

.middle[
## Power through Context
]

---

### Hypotheses are not identical

* We may know in advance that some hypotheses are more likely to be rejected than others.
  - Prior literature
  - Library size
* Using this information can improve power

[Histogram split into two, depending on known groups]

---

### Selective Inference

Step (1) is what distinguishes selective inference from ordinary statistical inference.

1. Search for interesting patterns.
1. Test whether they could have arisen by chance.

Looking for interesting contexts $\implies$ we are now doing selective inference.

---

### Example: Testing Pairs

Suppose we are testing associations between,

* SNPs $x_{1}, \dots, x_{I}$
* Histone Markers $y_{1}, \dots, y_{J}$

$H_{m}: \text{Cor}\left(x_{i}, y_{j}\right) = 0$.

Even for moderate $I, J$, this is many tests!

[Picture with links between two rows of circles]

---

### Pairwise Distance

We expect that most true associations are ``local,'' but we don't necessarily want to rule out long-range connections.

[Distance matrix showing expected rho[i, j]]]

---

### Generalization

* Group the distances into bins $1 , \dots, G$.
* We use different thresholds $\mathbf{t} = \left(t_{1}, \dots, t_{G}\right)$ across groups.

.pull-left[
R\left(\mathbf{t}\right) &:= \sum_{g} R_{g}\left(t_{g}\right) \\
\hat{\text{FDR}}\left(\mathbf{t}\right) &:= \frac{\sum_{g = 1}^{G} m_{g}t_{g}}{R\left(\mathbf{t}\right)}
]

.pull-right[
\begin{align*}
\text{maximize } &R\left(\mathbf{t}\right) \\
\text{subject to } &\hat{\text{FDR}\left(\mathbf{t}\right)} \leq q
\end{align*}
]

---

### Reformulation

The number of rejections can be derived from the CDF of the $p$-value histogram.

\begin{align*}
R_{g}\left(t_{g}\right) &= \hat{F}_{g}\left(t_{g}\right)
\end{align*}

---

### Optimization

We can plug this into generic optimization solvers:

.pull-right[
\begin{align*}
\text{maximize } & \sum_{g} m_{g}\hat{F}\left(t_{g}\right)
\text{subject to } &
\sum_{g = 1}^{G} m_{g}\left(t_{g} - m_{g}\hat{F}\left(t_{g}\right)\right) \leq q
\end{align*}
]

---

### Subtleties

* Cross-Weighting: As written, the threshold $t_{g}$ for a hypothesis $m$ in group $g$ may inadvertently depend on $p_{m}$.
* Convex Optimization: We can simplify the optimization by using monotone estimates of $\hat{F}_{g}$
* Regularization: Thresholds can be smoothed to reflect group similarity

---

### Code Demo

We first estimate the CDF of $p$-values within each group.

```{r}
```

---

### Code Demo

We next define the optimization problem.

```{r}
```

---

### Code Demo

We have learned to use a higher threshold for hypotheses with smaller pairwise distances. This focuses power on the most promising candidates.

```{r}
```

---

.middle[
## Calibration through Splitting
]

---

### Miscalibration

Often in computational genomics, traditional hypothesis testing assumptions
don't hold, so our $p$-values are not actually uniformly distributed.

[Show miscalibrated p-value histogram]

---

### Example

Imagine $x_{ij} \vert \text{disease = t} \sim \text{Poisson}\left(\lambda_{jt}\right)$ are genes whose expression potentially varies across disease status.

\begin{align*}
H_{0j}: \lambda_{j0} = \lambda{j1} \\
H_{1j}: \lambda_{j0} \neq \lambda_{j1}
\end{align*}

---

### Example

* If we used a Poisson model, there wouldn't be a problem. 
* What if we instead $\log\left(1 + x\right)$ transformed the data and ran two-sample $t$-tests?

.pull-left[
```{r}
M <- 100
lambdas <- rgamma(M)
x <- map(1:2, ~ rpois(M, lambdas))
```
]

.pull-right[
```{r}
x[[1]][1:50] <- rpois(50, 2 * lambdas)
t.test(x[[1]], x[[2]])
```
]

---

### Key Idea

We can avoid this problem if we can bypass $p$-values altogether.
  - Significance can be deduced from test statistics directly
  - We don't have to use BH to ensure FDR control

This is a highly adaptable idea. We'll discuss a simplification of \citep{dai2022}.

---

### Testing $\to$ Regression

We work with the original data $\*X \in \reals^{N \times M}$ and $\*y \in \reals^{N}$. 
 * E.g.: $y_{n} =$ disease state for patient $n$ and $x_{nm}$ expression level for gene $m$.

Consider the regression $\*y = \*X \*\beta + \epsilon$.
  * $H_{0m}: \hat{\beta}_{m}$ is symmetric around 0

---

### Symmetry and Mirrors

Randomly split rows into $\left(\*X^{(1)}, \*y^{(1)}\right)$ and $\left(\*X^{(2)}, \*y^{(2)}\right)$.

Mirror statistics have the form,
\begin{align*}
T_{m} &= \text{sign}\left(\hat{\beta}^{1}_{m}\hat{\beta}_{m}^{(2)}\right)f\left(\hat{\beta}^{(1)}_{m}, \hat{\beta}^{(2)}_{m}\right)
\end{align*}

where $\hat{\beta}^{(j)}$ are estimated on the separate splits.

---

### Symmetry and Mirrors

Mirror statistics measure the agreement in variable importances between splits.

[Qualitative figure of the estimates between splits]

Example: $\text{sign}\left(\hat{\beta}^{1}_{m}\hat{\beta}_{m}^{(2)}\right)\left[\frac{\hat{\beta}_{m}^{(1)} + \hat{\beta}_{m}^{(2)}}{2}\right]$

---

### Mirror Histogram

Let's revisit the Poisson problem. This is the histogram of $T_{m}$.

---

### Mirror Histogram

A reasonable strategy is to reject for all $T_{m}$ in the far right tail. How should we pick the threshold?

---

### FDR Estimation

By symmetry, the size of the left tail informs the number of nulls at each threshold $t > 0$:

\begin{align*}
\hat{\text{FDR}}\left(t\right) &= \frac{\absarg{T_{m} < -t}}{\absarg{T_{m} > t}}
\end{align*}

[Include a picture of flipping the null left with the true right tail]

---

### FDR Estimation

Maximize discoveries while controlling false discoveries:

\begin{align*}
\text{minimize} t \\
\text{subject to } \text{FDR}\left(t\right) \leq q
\end{align*}

---

### Multiple Splits

Issue:
  * A downside of this approach is that splitting samples reduces power.
  * It's possible to recover power by aggregating over multiple iterations of random splitting^[This is a recurring theme in the literature [give refs]].

Notation:
  * Call the $s^{text{th}}$ split ($s = 1, 2$) in the $k^{th}$ iteration $*X^{(s)}_{k}, y^{(s)}_{k}$
  * The associated regression estimates are $\hat{\beta}_{k}^{(s)}$.

---

### Aggregation Procedure

We need a mechanism for aggregating selections across each split.

[Draw the matrix of selections on both ends]