---
title: "Selective Inference in Computational Genomics"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    fig_caption: true
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title
background-image: url("figure/selective-cover.png")
background-size: cover


```{r, echo = FALSE, warnings = FALSE, message = FALSE}
library(RefManageR)
library(knitr)
library(tidyverse)
opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3, eval = TRUE)
opts_knit$set(eval.after = "fig.cap")

BibOptions(cite.style = "numeric")
bib <- ReadBib("references.bib")
```

.pull-left[
<div id="title">
Selective Inference for Computational Genomics
</div>
<div id="subtitle">
Computational Genomics Summer Institute <br/>
Kris Sankaran <br/>
14 | July | 2023 <br/>
https://github.io/krisrs1128/LSLab
</div>
]

---

### Learning Objectives

You will be able to help collaborators accurately resolve scientific issues by adapting high-power methods from selective inference.

By the end of this talk, you will be able to:

1. Discuss the role of selective inference abstractions in computational genomics settings.
1. Interpret $p$-value histograms and explain how they motivate the Benjamini-Hochberg procedure.
1. Improve power in large scale inference by focusing attention on the most promising contexts.
1. Diagnose miscalibration in large scale inference and apply data splitting to address it.

---

### Large Scale Inference

Notation
  * Hypotheses of interest: $H_{1}, \dots, H_{M}$
  * Associated $p$-values: $p_{1}, \dots, p_{M}$.

Goal: Reject as many non-null hypotheses as possible while controlling the False Discovery Rate, $\mathbb{E}\left[\left\|\frac{\mathrm{False Positives}\right\|}{\left\|\mathrm{Rejections}\right\|}].

---

### Examples

* Cancer: Is elevated immune cell expression of gene $m$ associated with improved survival rates?
* Microbiome: Is taxon $m$ associated with development of Type 1 diabetes?
* Epigenetics: Is SNP $i$ associated with histone marker $j$? Each $i-j$ pairs defines on test $H_{m}$.

--- 

### $p$-value histogram

* Under the null, the $p$-values follow a uniform distribution. 
* The spike near 0 are likely from the alternative
* $\pi_{0}$ denotes the true proportion of nulls

[ Image of p-value histogram ]

---

### $p$-value histogram

* Under the null, the $p$-values follow a uniform distribution. 
* The spike near 0 are likely from the alternative
* $\pi_{0}$ denotes the true proportion of nulls

[ show some with larger or smaller p-value histograms ]

---

### Benjamini-Hochberg

The BH procedure selects hypotheses in a way that controls the FDR at level $q$.

1. Sort the p-values: $p_{(1)} \leq p_{(2}) \leq \dots \leq p_{(m)}$
1. Find the largest $i$ such that $p_{(i)} leq \frac{i q}{m}$
1. Reject hypotheses associated with $p_{(1)} \leq \dots \leq p_{(i)}$ 

---

### Why?

At any threshold $t$, estimate

\begin{align*}
\hat{\text{FDR}}\left(t\right) &= \frac{\mathrm{Blue}}{\mathrm{Blue} + \mathrm{Purple}}
\end{align*}

[Figure of the p-values with the areas shaded in]

---

### Why?

Let $R\left(t\right)$ be the number of rejected hypotheses at threshold $t$. Then,

\begin{align*}
\hat{\text{FDR}}\left(t\right) &= \frac{\pi_{0}mt}{R\left(t\right)}
\end{align*}

---

### Why?

.pull-left[
Optimize:
\begin{align*}
\text{maximize } &R\left(t\right) \\
\text{subject to } &\hat{\text{FDR}} \leq q
\end{align*}
]

---

### Why?

.pull-left[
Optimize:
\begin{align*}
\text{maximize } &R\left(t\right) \\
\text{subject to } &\hat{\text{FDR}} \leq q
\end{align*}
]

.pull-right[
If we substitute $t = p_{(i)}$, then

\begin{align*}
\frac{\pi_{0}m p_{(i)}}{i} &\leq q \\
&\implies p_{(i)} \leq \frac{i q}{\pi_{0} m}
\end{align*}
]

(check this)

---

.middle[
## Power through Context
]

---

### Hypotheses are not identical

* We may know in advance that some hypotheses are more likely to be rejected than others.
  - Prior literature
  - Library size
* Using this information can improve power

[Histogram split into two, depending on known groups]

---

### Selective Inference

Step (1) is what distinguishes selective inference from ordinary statistical inference.

1. Search for interesting patterns.
1. Test whether they could have arisen by chance.

Looking for interesting contexts $\implies$ we are now doing selective inference.

---

### Example: Testing Pairs

Suppose we are testing associations between,

* SNPs $x_{1}, \dots, x_{I}$
* Histone Markers $y_{1}, \dots, y_{J}$

$H_{m}: \text{Cor}\left(x_{i}, y_{j}\right) = 0$.

Even for moderate $I, J$, this is many tests!

[Picture with links between two rows of circles]

---

### Pairwise Distance

We expect that most true associations are ``local,'' but we don't necessarily want to rule out long-range connections.

[Distance matrix showing expected rho[i, j]]]

---

### Generalization

* Group the distances into bins $1 , \dots, G$.
* We use different thresholds $\mathbf{t} = \left(t_{1}, \dots, t_{G}\right)$ across groups.

.pull-left[
R\left(\mathbf{t}\right) &:= \sum_{g} R_{g}\left(t_{g}\right) \\
\hat{\text{FDR}}\left(\mathbf{t}\right) &:= \frac{\sum_{g = 1}^{G} m_{g}t_{g}}{R\left(\mathbf{t}\right)}
]

.pull-right[
\begin{align*}
\text{maximize } &R\left(\mathbf{t}\right) \\
\text{subject to } &\hat{\text{FDR}\left(\mathbf{t}\right)} \leq q
\end{align*}
]

---

### Reformulation

The number of rejections can be derived from the CDF of the $p$-value histogram.

\begin{align*}
R_{g}\left(t_{g}\right) &= \hat{F}_{g}\left(t_{g}\right)
\end{align*}

---

### Reformulation

If we use a concave estimate of $\hat{F}_{g}$, this can be solved using off-the-shelf convex optimization solvers.

.pull-right[
\begin{align*}
\text{maximize } & \sum_{g} m_{g}\hat{F}\left(t_{g}\right)
\text{subject to } &
\sum_{g = 1}^{G} m_{g}\left(t_{g} - m_{g}\hat{F}\left(t_{g}\right)\right) \leq q
\end{align*}
]

---

### Code Demo

We first estimate the CDF of $p$-values within each group.

```{r}
```

---

### Code Demo

We next define the optimization problem.

```{r}
```

---

### Code Demo

We have learned to use a higher threshold for hypotheses with smaller pairwise distances. This focuses power on the most promising candidates.

```{r}
```

---

.middle[
## Calibration through Splitting
]

---

