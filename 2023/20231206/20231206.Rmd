---
title: "Expressive Interfaces for Multi-omics Simulation"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    fig_caption: true
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title
background-image: url("figures/cover.png")
background-size: cover

```{r, packages, echo = FALSE, warnings = FALSE, message = FALSE}
library(RefManageR)
library(STexampleData)
library(knitr)
library(tidyverse)
library(glue)
library(splines)
library(scDesigner)
library(gamlss)
library(gamboostLSS)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3, eval = TRUE)
opts_knit$set(eval.after = "fig.cap")
knit_hooks$set(output = scDesigner::ansi_aware_handler)
options(crayon.enabled = TRUE)
set.seed(20230120)

options(
  ggplot2.discrete.colour = c("#9491D9", "#3F8C61", "#F24405", "#8C2E62", "#F2B705", "#11A0D9"),
  ggplot2.discrete.fill = c("#9491D9", "#3F8C61", "#F24405", "#8C2E62", "#F2B705", "#11A0D9"),
  ggplot2.continuous.colour = function(...) scale_color_distiller(palette = "Spectral", ...),
  ggplot2.continuous.fill = function(...) scale_fill_distiller(palette = "Spectral", ...)
)

th <- theme_classic() +
  theme(
    panel.background = element_rect(fill="transparent"),
    strip.background = element_rect(fill="transparent"),
    plot.background = element_rect(fill="transparent", color=NA),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    legend.background = element_rect(fill="transparent"),
    legend.box.background = element_rect(fill="transparent"),
    legend.position = "bottom"
  )

theme_set(th)

BibOptions(cite.style = "numeric")
bib <- ReadBib("references.bib")
```

<div id="title">
Expressive Interfaces for Multi-omics Simulation
</div>

<br/>

<i>As the program notes say, "Dive into the gene pool to see evolution in action," and enjoy "genetic engineering in the privacy of your own home." 

Requires: 2.5 megabytes of system memory or 3 megabytes under System 7, and a hard drive.</i>

-- The New York Times, 1992

<i>Heard melodies are sweet, but those unheard <br/>
Are sweeter; therefore, ye soft pipes, play on... <br/></i>
-- Keats

<div id="subtitle">
Kris Sankaran <br/>
06 | December | 2023 <br/>
UW-Madison Statistics Seminar <br/>
</div>

---

### Why Simulate?

Simulation plays several roles in modern high-throughput biology.

* **Benchmarking**: They allow us to benchmark algorithms even when ground truth labels are
difficult (or impossible) to obtain.

* **Experimental Design**: We have to decide on cohorts, longitudinal sampling plans, and sequencing technologies, not to mention sample sizes.

* **Mechanisms**: Generative models can suggest improved mental models of biological processes.

---

### Why Simulate?

Simulation plays several roles in modern high-throughput biology.

* **Benchmarking**: They allow us to benchmark algorithms even when ground truth labels are
difficult (or impossible) to obtain.

* **Experimental Design**: We have to decide on cohorts, longitudinal sampling plans, and sequencing technologies, not to mention sample sizes.

* **Mechanisms**: Generative models can suggest improved mental models of biological processes.

<g style="font-size: 22px">
Examples: BASICS,
compcodeR,
deconvR,
dropsim,
ESCO,
FreeHi-C,
FreeHiCLite,
hierarchicell,
kersplat,
metaART,
MOSim,
MSstatsSampleSize,
Mimesys,
multiomics_networks_simulation,
muscat,
powsimR,
POWSC,
SCDD,
SCRIP,
Sim3C,
SimATAC,
SimFFPE,
sismonr,
spaSim,
sparseDOSSA,
Splat,
SPARSim,
SPsimSeq,
SparseDC,
SymSim,
ZINB-WaVE,
zingeR, ...
</g>

---

### A Grand Challenge

There is active interest in specializing these simulators to specific problem
and data contexts. However, most efforts remain isolated from one another.

*Many single-cell data analysis packages include their own ad hoc data simulators [111, 211, 241, 264, 349–353]. However, these simulators are usually not available as separate tools or even as a source code, tailored to specific problems studied in corresponding papers and sometimes not comprehensively documented, thus limiting their utility for the broad research community.*

-- Challenge 11 from "Eleven grand challenges in single-cell data science."

---

<g style="font-size: 36px">
<b>Main Idea: Apply interactive computing principles to multi-omics simulation.</b>
</g>

<img src="figures/Lego_Brick_4.svg" width=50/> <span style="color:#025E73">Modularity</span>: We should be able to build
problem-specific simulators by composing simple pieces.

<img src="figures/computer_mouse.png" width=35/> <span style="color:#D94E4E">Interactivity</span>: We should give domain
researchers agency in designing, evaluating, and modifying statistical
hypotheses.

<img src="figures/speech_bubbles.png" width=70/> <span style="color:#378C5C">Communication</span>: Model-building is a social
activity, and well-designed tools encourage substantive community engagement.

---

### scDesign

I have been trying put this philosophy into practice by through a new version of
the scDesign package. The simulation method has two main steps:

* Estimate gene-wise regression models using location-shape-scale families.
* Couple the quantiles from dependent pairs of features using a Gaussian or Vine Copula.

---

## Design


---

### Data Structures (Nouns)

We have defined separate classes for specifying,

* Gene-level probability models.
* Correlation structures across genes.

For the data itself, we rely on the `SummarizedExperiment` class.

* `colData` specifies the experimental design
* `assay` specifies the measured counts

```{r, read_data, echo = FALSE}
sce <- readRDS("data/PANCREAS_sce.rds")[1:10, ]
```

---

### Gene-Level Models

For each gene, we can specify the regression formula and distributional family.

```{r, setup_margins}
margins <- setup_margins(sce, ~ ns(pseudotime, df = 3),  ~ ZINBLSS())
margins
```

```{r, estimate_margins, echo = FALSE}
margins <- estimate(margins, sce)
```

---

### Gene-Level Models

Different parameters can have different formulas.

```{r modify_formulas}
formulas <- list("mu" = ~ ns(psuedotime, df = 3), "sigma" = ~ 1, "nu" = ~ 1)
setup_margins(sce, formulas,  ~ ZINBLSS())
```

---

### Copula Models

We can tie together a collection of marginals using a copula model.

```{r join_into_copula}
simulator <- new(
  "JointDistribution", 
  margins = margins, 
  dependence = copula_gaussian()
)
```

We can support different correlation structures across groups.

```{r modified_copula}
simulator <- new(
  "JointDistribution", 
  margins = margins, 
  dependence = copula_gaussian(~ cell_type)
)
```

---

### Wrapper

We can build both the marginal and joint distributions simultaneously.

.pull-left[
```{r wrap_into_simulator}
simulator <- setup_simulator(
  sce,
  ~ ns(pseudotime, df = 3),
  ~ ZINBLSS(),
  copula = copula_gaussian()
) |>
  estimate()
```
]

.pull-right[
```{r, print_simulator}
simulator
```
]

---

### Extensibility

For the marginals, we can borrow from existing LSS packages (gamboostLSS and gamlss) to implement a variety of gene-wise regressions,

* Gaussian, Gamma, Poisson, Binomial, Negative-Binomial, Zero-Inflated Poisson, Zero Inflated Negative Binomial,…

We can also build a unified interface to a variety of copula estimation routines,

* Gaussian and Student-t copulas with standard sample covariance, shrunken covariance, or graphical lasso precision estimates.
* Vine copulas for capturing higher-order moments.

---

### Operations (Verbs)

This syntax specifies a simulation model. What can we do with these building blocks?

Of course, we can **estimate** and **sample**.

More interestingly, we can also **plot**, **mutate**, **join**, **augment**.

---

### Plot Margins
```{r, echo = FALSE}
line_opts <- list(col = "#8C2E62", linewidth = 2)
ribbon_opts <- list(col = "#8C2E62", alpha = 0.1)
point_opts <- list(size = 0.4, alpha = 0.3)
```

```{r example_plot, out.width = 800}
plot(simulator, "pseudotime", line = line_opts, ribbon = ribbon_opts, point = point_opts) +
  facet_wrap(~ feature, ncol = 4)
```

---

### Plot Correlations

```{r correlation_plot, out.width = 600, fig.height = 6.5, fig.width = 10}
grid <- expand_colData(sce, "pseudotime")
samples <- sample(simulator, n_samples = 10, new_data = grid)
plot_correlations(samples, points_opts = list(size = 1.5, alpha = 1))
```

---

### <span style="color:#D94E4E">Interactivity</span> - Mutate

There are many reasons we might want to alter an initial simulator,
* Synthetic Nulls: We may want to formalize a synthetic null as the absence of a particular functional relationship.
* Iteration: We may want to improve the simulator’s goodness-of-fit by modifying the regression.
* Power Analysis: We may want to construct data from alternative experimental designs or biological signal strengths.

---

### Mutate

We can change the regression formula for specific genes. Syntax color highlights modifications that haven’t be re-fit.

```{r, mutate_margins}
margins |>
  mutate(Spp1:Cck, link = ~ pseudotime) 
```

---

### Mutate

```{r second_alteration, out.width = 800}
altered <- mutate(margins, Chga:Ins1, link = ~ pseudotime) |>
  estimate(sce)
plot(altered, sce, "pseudotime", line = line_opts, ribbon = ribbon_opts, point = point_opts) +
  facet_wrap(~ feature, ncol = 4, scales = "free_y")
```

---

### Mutate

We can also change the probability distributions.

```{r, probability_alteration}
margins |>
	mutate(c("Pyy", "Spp1"), family = ~ GaussianLSS())
```

---

### Mutate

And we can layer several on top of one another.

```{r, layered_alteration}
margins |>
  mutate(Chga:Ins1, link = ~ pseudotime) |>
  mutate(Pyy, link = ~ ns(pseudotime, 2) * cell_type) |>
  mutate(Iapp, link = list(mu = ~ ns(pseudotime, df = 3), sigma = ~ 1, nu = ~ 1))
```

---

### Mutate

1. Here is a more realistic example from a short longitudinal microbiome study.
2. We can use `mutate` to define a synthetic null where there is no disease effect for a known subset of genes.

.pull-three-quarters-left[
<img src="figures/nulls_unaltered.png"/>
]
.pull-three-quarters-right[
<img src="figures/pairwise_cors.png"/>
]

---

### Mutate

1. Here is a more realistic example from a short longitudinal microbiome study.
2. We can use `mutate` to define a synthetic null where there is no disease effect for a known subset of genes.

.pull-three-quarters-left[
<img src="figures/altered_ns.png"/>
]
.pull-three-quarters-right[
<img src="figures/pairwise_cors_altered.png"/>
]

---

### <span style="color:#025E73">Modularity</span> Join

If we can also establish simple rules for combining simulators, then there will be space for even more creativity.

<img src="figures/simulator_join_motivation.png"/>

```{r, echo = FALSE}
SCGEMMETH_sce <- readRDS("data/SCGEMMETH_sce.rds")
SCGEMRNA_sce <-readRDS("data/SCGEMRNA_sce.rds")

rownames(SCGEMMETH_sce) <- make.names(rownames(SCGEMMETH_sce))
rownames(SCGEMRNA_sce) <- make.names(rownames(SCGEMRNA_sce))
```

---

### <span style="color:#025E73">Modularity</span> Join

If we can also establish simple rules for combining simulators, then there will be space for even more creativity.

```{r illustrate_joins}
experiments <- list(methylation = SCGEMMETH_sce, rna = SCGEMRNA_sce)
families <- list(~ BI(), ~ GaussianLSS())
sims <- experiments |>
  map2(families, \(x, y) setup_simulator(x, ~ cell_type, y))
```

---

### Join (Copula)

One approach is to merge the list of marginal distributions and re-estimate the joint distribution.

```{r, join_simulators_glasso, eval = FALSE}
sim_joined <- map(sims, estimate, nu = 0.1) |>
  join_copula(copula_glasso())
```

This assumes that we have samples where all features are measured.

.center[
<img src="figures/simulator_join_features.png" width = 680/>
]

---

### Join (Conditioning)

Alternatively, we can combine two simulators by conditioning them on shared latent structure.

```{r join_simulators}
sim_joined <- join_pamona(sims)
```

.center[
<img src="figures/simulator_join.png" width = 800/>
]

---

### Join (Conditioning)

This used partial manifold alignment to learn shared latent variables across assays. This works even in the diagonal integration setting.

```{r print_joined}
sim_joined
```

```{r, spatial_download, echo = FALSE}
spe <- Visium_humanDLPFC()
gene_order <- order(rowSums(counts(spe)), decreasing = TRUE)
spatial_experiment <- spe[gene_order[1:10], ]
```

---

### <span style="color:#025E73">Modularity</span> - Augment

We want a unified interface that works across diverse data types. One way to
create consistency is to **augment** the general `SummarizedExperiment` with
domain-specific structure .

For example, this makes spatial information accessible within the regression:

```{r, spatial_estimation}
spatial_experiment <- augment(spatial_experiment)

simulator <- spatial_experiment |>
  setup_margins(~ ns(pxl_col_in_fullres, 3) * ns(pxl_row_in_fullres, 3), ~ NBinomialLSS()) |>
  estimate(spatial_experiment)
```

---

### <span style="color:#025E73">Modularity</span> - Augment

For example, this makes spatial information accessible within the regression:

```{r plot_spatial, fig.height = 3.5, fig.width = 9, echo = FALSE}
features <- c("pxl_col_in_fullres", "pxl_row_in_fullres")
plot_bivariate(
    simulator, spatial_experiment[, 1:5e2], features,
    feature_names = c("ENSG00000198899", "ENSG00000198888", "ENSG00000167996")
  ) +
  labs(
    "fill" = expression(log(1 + count)),
    "color" = expression(log(1 + count))
  )
```

---

## Case Studies

---

### Overview

1. These models have too many parameters to be directly useful for data analysis.
	1. "All models are wrong, but these are not wrong enough."
2. They *can* be useful indirectly,
	1. Providing ground truth for benchmarking models with fewer, more interpretable parameters.
	2. Carrying out systematic power analysis that is informed by past data we have available.

---

### Case Study 1: Multi-omics Power Analysis

1. In practice, most power analysis are univariate, e.g., to guide differential expression.
2. How should we do multivariate power analysis, especially when we have several tables?

---

### Example

For concreteness, let’s revisit the microbiome + metabolome mouse study CCA from the F1000 Workflow paper. This had 12 samples.
1. How does estimation quality improve with sample size?
2. Is it worth gathering unpaired samples? (mosaic designs)

.center[
<img src="figures/cca_f1000.gif" width=650/>
]

---

### Part 1: Estimate Simulators

1. Fit ZINB models to the microbiome.
2. Fit Gaussian models to the metabolome.
3. Join them using highly regularized covariance estimates.

.center[
  <img src="figures/cca_microbiome_hist.png"/>
]

---

### Part 1: Estimate Simulators

1. Fit ZINB models to the microbiome.
2. Fit Gaussian models to the metabolome.
3. Join them using highly regularized covariance estimates.

.center[
  <img src="figures/cca_metab_hist.png"/>
]

---

### Part 2: Hypothetical Experiments
.pull-left[
1. Across sample sizes $n$, we simulate new data, fit sparse CCA, and identify a
basis $\hat{V}_{n}$ spanning the $K = 5$ left and right sparse CCA factors
1. We use $\hat{V}_{5000}$ as a reference and compute canonical angles with all
smaller sample sizes.
]

.pull-right[
<img src="figures/canonical_angles_paper.png"/>
Figure from `r Citep(bib, "Arikawa2018TheoreticalFF")`.
]


---
### Non-Mosaic Case

With more samples, the canonical angles shrink in a predictable way.

.center[
<img src="figures/canonical_angles.png" width=750/>
]

---

### Mosaic Case

Here, we have allowed the sample sizes to differ and use KNN imputation to run
CCA on an imputed table.

.center[
<img src="figures/mosaic_example.png" width=750/>
]

---

### Case Study 2: Multi-Study Comparison

From _Of P-Values and Bayes: A Modest Proposal_ by Steve Goodman:

> Imagine a number that does not tell us what we know, but how much we have learned… [W]e should incorporate a Bayesian framework into our writing, and not just our speaking. We should describe our data as one source of information among many that make a relationship either plausible or unlikely. The use of summaries such as the Bayes factor encourages that, while use of the P-value makes it nearly impossible. 

---

### Case Study 2: Multi-Study Comparison

From _Of P-Values and Bayes: A Modest Proposal_ by Steve Goodman:

> Imagine a number that does not tell us what we know, but how much we have learned… [W]e should incorporate a Bayesian framework into our writing, and not just our speaking. We should describe our data as one source of information among many that make a relationship either plausible or unlikely. The use of summaries such as the Bayes factor encourages that, while use of the P-value makes it nearly impossible. 

---

### Case Study 2: Multi-Study Comparison

1. Simulators offer a way of encoding community consensus. We are interested in how evidence accumulates and consensus evolves.
2. We will work with the `curatedMetagenomicsData`, which includes 12 studies of colorectal cancer (CRC) processed with the same pipeline.

---

### Association from first study

For each taxon $j$, we fit two $\text{ZINB}\left(\mu_{j}, \sigma_{j}, \nu_{j}\right)$ models:

\begin{align}
H_{j1}: \left(\mu_j, \sigma_j,\nu_j\right) &\sim \log\left(\text{Sequencing Depth}\right) + \text{CRC}\\
H_{j0}: \left(\mu_j, \sigma_j,\nu_j\right) &\sim \log\left(\text{Sequencing Depth}\right)
\end{align}

Given data $X^{(1)}$ from study 1, we compute $P\left(H_{j1} \vert X^{(1)}\right)$, assuming $P\left(H_{j1}\right) = 0.1$ a priori and that $H_{j1}$ and $H_{j0}$ are the only possible states of the world.

---

### Association from first study

These are the taxa with the largest value of $P\left(H_{j1} \vert X^{(1)}\right)$.

.center[
<img src="figures/initial_selection.png" width=750/>
]

---

### Remaining studies

We can see how this changes as the number of studies is increased. We now consider,
\begin{align}
H_{j1}: \left(\mu_j, \sigma_j,\nu_j\right) &\sim \log\left(\text{Sequencing Depth}\right) + \text{Study ID} + \text{CRC}\\
H_{j0}: \left(\mu_j, \sigma_j,\nu_j\right) &\sim \log\left(\text{Sequencing Depth}\right) + \text{Study ID}
\end{align}
and fit associated ZINB models using all data from studies $X^{(1)}, \dots, X^{(K)}$.

This lets us track $P\left(H_{j1} \vert X^{(1)}, \dots, X^{(K)}\right)$.

---

### Remaining Studies

This provides a simple summary of how evidence has evolved as more studies are
completed.

.center[
<img src="figures/hypothesis_evolution.png" width = 900/>
]

---

### Remaining Studies

We can focus in on some of the more interesting curves, and the low-level data
seem consistent with the high-level summary.

.center[
<img src="figures/hypothesis_evolution_example.png" width = 900/>
]

---

### Precise Technology $\neq$ Precise Thought

1. Translating scientific hypotheses in quantitative models is more challenging
than is widely appreciated. This arguably contributes to the ongoing
reproducibility crisis `r Citep(bib, "")`

1. Generative models train researchers in this skill, and effective interactive
computing interfaces can accelerate their adoption.

---

### Memos for the New Millennium

<table id="images" style="width: 100%; border: none;">
<tr>
<td style="width: 20%;">
  <img src="figures/cloud.png" width=100px/> 
</td>
<td style="width: 20%;">
  <img src="figures/speedometer.svg" width=55px/> 
</td>
<td style="width: 20%;">
<img src="figures/compass.jpeg" width=60px/> 
</td>
<td style="width: 20%;">
<img src="figures/microscope.jpeg" width=50px/> 
</td>
<td style="width: 20%;">
<img src="figures/galaxy.png" width=80px/> 
</td>
</tr>
</table>
Lightness: A well-designed interface brings a kind of effortlessness to
statistical thought.

Quickness: We value the ability quickly experiment with and compare hypotheses.

Exactitude: Simulations require precision in scientific hypotheses.

Visibility: Simulation can bring biological mechanisms to the surface.

Multiplicity: We must become comfortable working simultaneously with data
with multiple different forms.

---

### Acknowledgements

* Members of my research group - Hanying Jiang, Shuchen Yan, Zhuoyan Xu, Kaiyan Ma, Margaret Thairu, and Mason Garza
* Members of the JSB Lab (UCLA) and the MixOmics group (University of Melbourne).
* Funding mechanism: NIGMS R01GM152744.

---

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 1, end = 3)
```

---

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 4, end = 7)
```

