---
title: "Visualization in Deep Learning: Theme and Variations"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    fig_caption: true
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
---

class: title
background-image: url("figures/svcca-training.giv")
background-size: cover

```{r, packages, echo = FALSE, warnings = FALSE, message = FALSE}
library(knitr)
library(RefManageR)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3, eval = TRUE)
opts_knit$set(eval.after = "fig.cap")
BibOptions(cite.style = "numeric")
bib <- ReadBib("references.bib")
```

<div id="title">
Visualization in Deep Learning: Theme and Variations
</div>

<div id="subtitle">
Kris Sankaran <br/>
<a href="https://go.wisc.edu/pgb8nl">go.wisc.edu/pgb8nl</a> <br/>
16 | November | 2023 <br/>
Machine Learning Lunch Meetings
</div>

---

### Theme: Representations of DL Models

We often talk about how deep learning models learn higher-order representations from the data they are provided.

<img src="figures/bengio_representations.png"/>

---

### Theme: Representations of DL Models

What representations help with our reasoning about the models themselves?

<img src="collage-nnet-architecture-loss-curves-transformer-picture.png"/>

---

### Audience Question

What kinds of visualizations do you make in your daily machine learning research (and not just for publication)?

Discussion Page: [go.wisc.edu]

---
### Variations

Visualization is often used to:
1. Summarize training dynamics.
2. Reason about errors and predictions.
3. Describe memory and representation learning mechanisms.

These abstractions help with:
1. Training and improving real-world models. (1, 2)
2. Guiding research through improved mental models. (1, 3)
3. Tying models into broader scientific discussion. (3)

---

### Variations

I’ll be drawing examples mainly from two of my projects:

2. **Glacier Ecosystem Mapping**: Application of satellite image segmentation to climate change adaptation and disaster preparedness.
3. Remembrances of States Past: A visual analysis of "time warping" in sequence models.

I will highlight <span style="color:red"/>general visualization principles</span> in red.

<img src="figures/glacier_overview.png"/>
---

### Variations

I’ll be drawing examples mainly from two of my projects:

2. Glacier Ecosystem Mapping: Application of satellite image segmentation to climate change adaptation and disaster preparedness.
3. **Remembrances of States Past**: A visual analysis of "time warping" in sequence models.

I will highlight <span style="color:red"/>general visualization principles</span> in red.

<img src="figures/remembrances_overview.png"/>

---

## Visualizing Training Dynamics

---
### Loss Curves

Despite (or because of?) their simplicity, these plots have been one of the most impactful visualizations in modern machine learning.

<img src="figures/loss_example.png"/>

---

### Loss Curves

They highlight whether the model is over/underfitting. This has immediate consequences for model architecture, optimization, and regularization.

<img src="figures/loss_example.png"/>

---
### Example: Counting Crossings

In this toy problem, we apply a sequence model (with gated recurrent units) to count the number of times a curve has crossed the grey band.

.center[
<iframe width="800" height="484" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past?cells=chart"></iframe>
]

---

### Example: Counting Crossings

The example dataset are a collection of labeled pairs: 

* $\mathbf{x}_{i} \in \mathbb{R}^{100}$: A random spline trajectory stored as a long vector.
* $y_i$: The number of times the trajectory crosses the interval $\left[0, 1\right]$.

.center[
<iframe width="100%" height="400" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past@1310?cells=chart9"></iframe>
]

---

### Loss Curves

It's interesting to visualize the evolution of instance-level errors, especially
examples that remain difficult to predict late in training.

.center[
<iframe width="950" height="500" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past@1311?cells=chart11"></iframe>
]

---

### <span style="col: red;">Dynamic Linking</span>

This visualization applies dynamic linking. By coordinating interaction across several panels, we can encode complementary views of the same data.

(NYT Linked Views)

---
### Activations and Gradients

.pull-left[
More than losses, it can be worthwhile to visualize feature maps and gradients
throughout the training process.

These are activations from a UMAP model trained to segment glaciers `r
Citep(bib, "zheng2022")`. The skip connections prevented the deepest layer in
the architecture from ever being learned!
]

.pull-right[
<img src="figures/glacier_representations.png" width=470/>
]

---

### Activations and Gradients

More than losses, it can be worthwhile to visualize feature maps and gradients throughout the training process.

<img src="figures/gradient_vis.png"/>

Here is an example from Shixia Liu’s group that shows the value of visualizing gradients during training.

---

## Visualizing Errors and Predictions

---

### Visualizing Errors

We fit satellite image segmentation models to datasets on building footprints and glacier labels, respectively. Here are examples that were flagged as being especially poor quality.

.center[
<img src="figures/img_6560_kitsap4.png" width=250/>
<img src="figures/pred_6560_kitsap4.png" width=250/>
<img src="figures/mask_6560_kitsap4.png" width=250/>
]

In both cases, our worst examples are due to label noise. Can you tell what happened?

---

### Visualizing Errors

We fit satellite image segmentation models to datasets on building footprints and glacier labels, respectively. Here are examples that were flagged as being especially poor quality.

.center[
<img src="figures/img_6560_kitsap4.png" width=250/>
<img src="figures/pred_6560_kitsap4.png" width=250/>
<img src="figures/mask_6560_kitsap4.png" width=250/>
]

In both cases, our worst examples are due to label noise. Can you tell what happened?

---

For problems where each sample is associated with a continuous accuracy measure, it is helpful to look at representatives from across the continuum.

<img src="figures/glacial_lakes_grid.gif" width=700/>

Different models can have different failure modes, and this kind of visualization compactly represents that.

---
<span style="color: red"/>Small Multiples</span>

In visualization, the idea of repeating a view across many parallel instances is called small multiples. They can reveal substantial information at a single glance.

<img src="figures/small_multiples_example.png"/>

---

<span style="color: red"/>Data-to-Ink</span>

.pull-left[
We were also careful to remove extraneous plot elements (e.g., unnecessary tick marks and grid lines). This is line with the goal of maximizing data-to-ink `r Citep(bib, "tufte1985")`.]

.pull-right[
<img src="figures/glacial_lakes_grid.gif" width=800/>
]

---

### Smoothed Error Rates

This is the result of a PCA on the activations at the last layer of the building footprint segmentation model. For the background, we smoothed the error metric across training examples.

<iframe src="https://adrijanik.github.io/unet-vis#div_main" width=1000 height=400/>

---

### Navigating Predictions

How might a model's predictions guide decision making?

.pull-left[
We worked on a project with ICIMOD to identify regions that lakes that were growing rapidly. These are a risk factor for glacial lake outburst floods.
]

.pull-right[
<img src="figures/nyt_glacier.png"/>
]

---

### Navigating Predictions

From predicted segmentations, we could fit trends to each lake's estimated area.
This volcano plot shows those that need more proactive monitoring.

.center[
<img src="figures/volcano_plot.gif" width=640/>
]

---

### Navigating Predictions

We also implemented a Shiny App to look up images from lakes with interesting trends.

<iframe width=1000 src="https://krisrs1128.shinyapps.io/glacial_lake_visualization/" height=450/>

---
### <span style="col: red;">Focus-plus-Context</span>

This is an instance of the focus-plus-context principle `r Citep(bib, "heer2004")`. The idea is to let the reader zoom into patterns of interest without losing relevant context.

.center[
<img src="figures/doitree_dmoz.gif" width=800/>
]

---

## Visualizing Representations

---
### Goals of Representation Analysis

Deep learning models should sense higher-order abstractions. We can evaluate this by analyzing their learned representations.

1. How do architectural components compare, and how does it relate to performance differences?
2. Why do common training practices like transfer learning and normalization seem to help?
3. How do data-driven representations relate to concepts designed by human experts?

---

### Visualizing LSTMs

A classic paper in this field looked at feature activations in character-level sequence models. It discovered representations related to sequence position and quotations, for example.

<img src="figures/lstm-activations-1.png"/>

---

### Visualizing LSTMs

This paper helped demystify the mechanics of LSTM models. We could see how gating prevented important pieces of memory from being overwritten over long stretches of text.

<img src="figures/lstm-activations-2.png"/>

---

### Parking lot or…?

Back to the building footprint labeling task, here are two images we found with similar feature activations.
(todo: check which layers exactly)

.pull-left[
<img src="figures/cars.png" width=400/>
]
.pull-right[
<img src="figures/graves.png" width=400/>
]

---

### Cemetery

This layer activates a particular set of neurons that encodes  "clustered rectangularness."

.pull-left[
<img src="figures/cars.png" width=400/>
]
.pull-right[
<img src="figures/graves.png" width=400/>
]

---

### Counting Model

Let’s look at features from the counting model. The few layers
encode the $y$-value of the trajectory. Later ones count crossings.

<iframe width="100%" height="484" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past@1323?cells=chart7"></iframe>

---
### Time Warping

My main interest in this example was actually the "time warping" phenomenon. This is related to an algebraic observation about the structure of gated recurrent units.

(add the derivation)

---
### Time Warping

During "steep" regions of the warping function, we experience time moving more rapidly. In the original frame of reference, we forget more quickly.
 
<iframe width="100%" height="472" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past@1323?cells=chart10"></iframe>
 
---

### Time Warping

In our trained model, we can analyze the gatings $g_{t}$ to see how the counting model warps time.

<iframe width="100%" height="484" frameborder="0"
  src="https://observablehq.com/embed/@krisrs1128/remembrances-of-states-past@1323?cells=chart8"></iframe>

---

### Other Useful Ideas

* **Linear Probes**: To see whether a layer has learned particular "concept," try predicting using its activations to learn a linear classifier. See also concept activation.
* Centered Kernel Alignment: To compare a pair of high-dimensional representations, use a measure of multivariate association.

<img src="figures/linear_probes.png"/>

---

### Other Useful Ideas

* Linear Probes: To see whether a layer has learned particular "concept," try predicting using its activations to learn a linear classifier. See also concept activation.
* Centered Kernel Alignment: To compare a pair of high-dimensional representations, use a measure of multivariate association.

<img src="figures/cka_alignment.png"/>

---
### Learned Representations in Science

Scientific foundation models are gaining prominence, and it’s common to make dimensionality reduction plots from them. Can we make something that encourages more precise discourse?

.center[
<iframe src="https://esmatlas.com/explore?at=1%2C1%2C21.999999344348925" width=950 height=350/>
]

---
### Learned Representations in Science

Scientific foundation models are gaining prominence, and it’s common to make dimensionality reduction plots from them. Can we make something that encourages more precise discourse?

<img src="figures/scgpt-atlas.png"/>

---

### Intriguing Experiment

`r Citep(bib, c("viegas", "manning"))` presented connections between linguistics and BERT embeddings. For example, they found that embedding and formal parse-tree distances were closely related.

<img src="figures/parse-tree.png"/>

---

### Intriguing Experiment

They also saw how the embeddings reflect word sense disambiguation and built an app to interactively query different words.

<img src="figures/word-sense.png"/>

---

### Why do these work?

I like how these visualizations:
(1) Encourage readers to engage with existing mental models. 
(2) Provide domain-relevant context for interacting with learned representations.

This seems like a promising way to balance efficiency and agency in theory building. Hopefully we can avoid the "kaggleization of science" `r Citep(bib, "manning_interview")`.

---

### Multi-omics analog?

How might these ideas play out in multi-omics foundation models?

* Gene regulatory networks <—> parse trees. Both provide simple abstractions for reasoning about complex processes.
* Gene-sense disambiguation. A protein’s purpose can depend on its cellular surroundings, and it’s possible that foundation models have learned to represent this.

<img src="figures/multi-omics-graph.png"/>

---

### Conclusion

I hope that you have learned a few visualization ideas that can help your research and collaborations (Discussion: go.wisc.edu). 

Some final thoughts:

1. Training, evaluation, and representation analysis all provide opportunities for thoughtful visualization.
2. When we build deep learning models, we are part of a human-machine system, and visualization is an important part of the link.

---

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 1, end = 3)
```
